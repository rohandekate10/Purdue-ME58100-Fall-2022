{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "\n",
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.,   17.,   35.,   98.],\n",
       "       [  17.,   35.,   98.,  282.],\n",
       "       [  35.,   98.,  282.,  996.],\n",
       "       [  98.,  282.,  996., 2778.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define Matrix A\n",
    "A = np.array([[8,17,35,98],\n",
    "              [17,35,98,282],\n",
    "              [35,98,282,996],\n",
    "              [98,282,996,2778]], float)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.3 ,  25.56,  67.89, 203.42])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define vector b\n",
    "b = np.array([13.3,25.56,67.89,203.42], float)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18504801,  0.98813711,  0.02661394, -0.03009627])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution Using Numpy Library for Verification\n",
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial estimate vector x0 is vector 1\n",
    "\n",
    "x0 = np.array([1,1,1,1], float)\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum iteration variable\n",
    "itr_max = 50\n",
    "\n",
    "# Define tolerance\n",
    "tol = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -144.7 ,  -406.44, -1343.11, -3950.58])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the initial search direction\n",
    "r0 = np.dot(A,x0) - b\n",
    "d0 = -r0\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17597158.3721"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta0 = np.dot(r0.T,r0)\n",
    "delta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 144.7 ,  406.44, 1343.11, 3950.58])],\n",
       " [array([ -144.7 ,  -406.44, -1343.11, -3950.58])],\n",
       " [17597158.3721],\n",
       " [],\n",
       " [],\n",
       " [array([1., 1., 1., 1.])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "r.append(r0)\n",
    "\n",
    "d = []\n",
    "d.append(d0)\n",
    "\n",
    "delta = []\n",
    "delta.append(delta0) \n",
    "\n",
    "# lambda_m\n",
    "step_size = []\n",
    "\n",
    "x = []\n",
    "x.append(x0) \n",
    "\n",
    "alpha = []\n",
    "\n",
    "r,d,delta,step_size,alpha,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to iteratively solve Ax = b for x, with the Conjugate Gradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 1\n",
      "[ 0.95418747  0.87131967  0.57476665 -0.25076754]\n",
      "Norm: 1.2507675366289985\n",
      "\n",
      "Iteration # 2\n",
      "[ 1.02863352  0.9790844  -0.00595854 -0.06090805]\n",
      "Norm: 0.5807251872959931\n",
      "\n",
      "Iteration # 3\n",
      "[0.58642278 0.29070283 0.05422904 0.00357355]\n",
      "Norm: 0.688381563191789\n",
      "\n",
      "Iteration # 4\n",
      "[-0.18504801  0.98813711  0.02661394 -0.03009628]\n",
      "Norm: 0.7714707918280524\n",
      "\n",
      "Iteration # 5\n",
      "[-0.18504801  0.98813711  0.02661394 -0.03009627]\n",
      "Norm: 3.3587912728894054e-09\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[-0.18504801  0.98813711  0.02661394 -0.03009627]\n"
     ]
    }
   ],
   "source": [
    "norm = [] # Initialize list to store error norm values\n",
    "\n",
    "for m in range(0, itr_max+1): # Start the iteration loop\n",
    "    print(f'Iteration # {m+1}')\n",
    "    u = np.dot(A,d[m])\n",
    "    \n",
    "    lambda_m = delta[m] / np.dot(d[m],u)\n",
    "    #lambda_m = delta[m] / d[m].T*u\n",
    "    step_size.append(lambda_m)\n",
    "    \n",
    "    x_new = x[m] + lambda_m * d[m]\n",
    "    print(x_new)\n",
    "    x.append(x_new)\n",
    "    \n",
    "    r_new = r[m] + np.dot(lambda_m, u)\n",
    "    #r_new = r[m] + lambda_m*u\n",
    "    r.append(r_new)\n",
    "    \n",
    "    delta_new = np.dot(r_new,r_new)\n",
    "    #delta_new = r_new.T*r_new\n",
    "    delta.append(delta_new)\n",
    "    \n",
    "    #Stop condition \n",
    "    stop = np.linalg.norm(x[-1] - x[-2], ord=np.inf)\n",
    "    norm.append(stop)\n",
    "    print(f'Norm: {stop}')\n",
    "    print()\n",
    "    \n",
    "    #if np.sqrt(delta_new) <= tol:\n",
    "    if stop <= tol:\n",
    "        #print()\n",
    "        print('Solution Converged!')\n",
    "        print('Best Approximated Solution: ')\n",
    "        print(x_new)\n",
    "        break\n",
    "    \n",
    "    #elif np.sqrt(delta_new)>=1e4:\n",
    "    elif stop >= 1e4:\n",
    "        #print()\n",
    "        print('Solution Diverged!')\n",
    "        print('Latest Approximated Solution: ')\n",
    "        print(x_new)\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        alpha_new = delta_new/delta[m]\n",
    "        alpha.append(alpha_new)\n",
    "        \n",
    "        d_new = -r_new + np.dot(alpha_new,d[m])\n",
    "        #d_new = -r_new + alpha_new*d[m]\n",
    "        d.append(d_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0 =  -0.18504801159030457\n",
      "a 1 =  0.9881371096175827\n",
      "a 2 =  0.02661394481160957\n",
      "a 3 =  -0.030096273869212188\n"
     ]
    }
   ],
   "source": [
    "# Values for vector x\n",
    "for idx,a in enumerate(x_new.tolist()):\n",
    "    #print(idx)\n",
    "    #print(a)\n",
    "    print('a',idx,'= ',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.3 ,  25.56,  67.89, 203.42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "np.dot(A,x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2507675366289985,\n",
       " 0.5807251872959931,\n",
       " 0.688381563191789,\n",
       " 0.7714707918280524,\n",
       " 3.3587912728894054e-09]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEYCAYAAACp5wpbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = range(1,len(norm)+1)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(iteration,norm,'-o');\n",
    "plt.xlabel('Iteration #')\n",
    "plt.ylabel(r'$|| x_{n+1} - x_{n} ||_{\\infty}$')\n",
    "plt.title(r'Plot of $|| x_{n+1} - x_{n} ||_{\\infty}$ vs Iteration Number')\n",
    "plt.grid()\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Norm</th>\n",
       "      <th>Approximate Solution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.250768e+00</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.807252e-01</td>\n",
       "      <td>[0.95418747056123, 0.8713196650650056, 0.5747666453731416, -0.25076753662899853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.883816e-01</td>\n",
       "      <td>[1.028633522902516, 0.979084397509264, -0.005958541922851501, -0.06090805461860918]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.714708e-01</td>\n",
       "      <td>[0.5864227801183595, 0.290702834317475, 0.05422904495781623, 0.0035735456405526222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.358791e-09</td>\n",
       "      <td>[-0.18504801170969298, 0.9881371092768441, 0.026613943635674524, -0.03009627722800346]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Error Norm  \\\n",
       "Iteration #                 \n",
       "1            1.250768e+00   \n",
       "2            5.807252e-01   \n",
       "3            6.883816e-01   \n",
       "4            7.714708e-01   \n",
       "5            3.358791e-09   \n",
       "\n",
       "                                                                               Approximate Solution  \n",
       "Iteration #                                                                                          \n",
       "1            [1.0, 1.0, 1.0, 1.0]                                                                    \n",
       "2            [0.95418747056123, 0.8713196650650056, 0.5747666453731416, -0.25076753662899853]        \n",
       "3            [1.028633522902516, 0.979084397509264, -0.005958541922851501, -0.06090805461860918]     \n",
       "4            [0.5864227801183595, 0.290702834317475, 0.05422904495781623, 0.0035735456405526222]     \n",
       "5            [-0.18504801170969298, 0.9881371092768441, 0.026613943635674524, -0.03009627722800346]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "df = pd.DataFrame(list(zip(norm, x)), index =[*range(1, len(norm)+1)], \n",
    "                  columns =['Error Norm','Approximate Solution'])\n",
    "df.index.names = ['Iteration #']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conjugate Gradient Method takes 5 iterations to converge for the given system of equations.\n",
    "* The error norm is not consistently decreasing. At the 5th iteration, the error norm is close to 0 and meets the convergence criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pagebreak$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-78.8,  48.8,   0. ,   0. ,   0. ,   0. ],\n",
       "       [ 30. , -78.8,  48.8,   0. ,   0. ,   0. ],\n",
       "       [  0. ,  30. , -78.8,  48.8,   0. ,   0. ],\n",
       "       [  0. ,   0. ,  30. , -78.8,  48.8,   0. ],\n",
       "       [  0. ,   0. ,   0. ,  30. , -78.8,  48.8],\n",
       "       [  0. ,   0. ,   0. ,   0. ,  30. , -78.8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[-78.8,48.8,0,0,0,0],\n",
    "              [30,-78.8,48.8,0,0,0],\n",
    "              [0,30,-78.8,48.8,0,0],\n",
    "              [0,0,30,-78.8,48.8,0],\n",
    "              [0,0,0,30,-78.8,48.8],\n",
    "              [0,0,0,0,30,-78.8]], float)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.04,   0.  ,   0.  ,   0.  ,   0.  , -10.01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([-1.04,0,0,0,0,-10.01],float)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10258806, 0.14434301, 0.17001204, 0.18579218, 0.19549309,\n",
       "       0.20145676])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution Using Numpy Library for Verification\n",
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to iteratively solve Ax = b for x, with Gauss-Seidel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:  [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [0.01319797 0.00502461 0.00191292 0.00072827 0.00027726 0.12713601]\n",
      "Norm: 0.12714\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [0.01630966 0.00739391 0.00326595 0.00141509 0.07927272 0.15721042]\n",
      "Norm: 0.07900\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [0.01777694 0.00879044 0.00422296 0.05070047 0.11666095 0.17144452]\n",
      "Norm: 0.04929\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [0.01864179 0.00971237 0.03509586 0.08560825 0.13876574 0.17986005]\n",
      "Norm: 0.03491\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [0.01921273 0.02904899 0.06407554 0.11033038 0.15338937 0.18542742]\n",
      "Norm: 0.02898\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [0.0311877  0.05155479 0.08795389 0.12847738 0.16374594 0.18937028]\n",
      "Norm: 0.02388\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [0.0451253  0.07164859 0.10684205 0.14208202 0.17136714 0.19227175]\n",
      "Norm: 0.02009\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [0.05756918 0.08808334 0.12152415 0.15239138 0.17708887 0.19445008]\n",
      "Norm: 0.01643\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [0.06774705 0.10105063 0.13284541 0.16024491 0.18142781 0.19610196]\n",
      "Norm: 0.01297\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [0.07577755 0.11111907 0.14154218 0.16624292 0.1847343  0.19736078]\n",
      "Norm: 0.01007\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [0.08201282 0.11887872 0.14821087 0.17082944 0.18726001 0.19832234]\n",
      "Norm: 0.00776\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [0.08681829 0.12483806 0.15332003 0.1743387  0.18919151 0.19905768]\n",
      "Norm: 0.00596\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [0.09050885 0.12940715 0.15723278 0.17702448 0.19066941 0.19962033]\n",
      "Norm: 0.00457\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [0.09333844 0.13290752 0.16022869 0.1790803  0.19180052 0.20005096]\n",
      "Norm: 0.00350\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [0.09550618 0.13558814 0.16252237 0.18065402 0.19266634 0.20038059]\n",
      "Norm: 0.00268\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [0.09716626 0.1376406  0.16427835 0.18185873 0.19332912 0.20063291]\n",
      "Norm: 0.00205\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [0.09843733 0.13921197 0.16562265 0.18278097 0.19383649 0.20082607]\n",
      "Norm: 0.00157\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [0.09941046 0.14041497 0.16665178 0.18348698 0.1942249  0.20097395]\n",
      "Norm: 0.00120\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [0.10015546 0.14133592 0.16743962 0.18402746 0.19452224 0.20108715]\n",
      "Norm: 0.00092\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [0.1007258  0.14204096 0.16804275 0.18444121 0.19474986 0.20117381]\n",
      "Norm: 0.00071\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [0.10116242 0.1425807  0.16850447 0.18475796 0.19492412 0.20124015]\n",
      "Norm: 0.00054\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [0.10149668 0.14299389 0.16885793 0.18500044 0.19505752 0.20129093]\n",
      "Norm: 0.00041\n",
      "\n",
      "Iteration #: 23\n",
      "Approximated Solution:  [0.10175256 0.1433102  0.16912852 0.18518607 0.19515964 0.20132981]\n",
      "Norm: 0.00032\n",
      "\n",
      "Iteration #: 24\n",
      "Approximated Solution:  [0.10194845 0.14355235 0.16933567 0.18532818 0.19523782 0.20135958]\n",
      "Norm: 0.00024\n",
      "\n",
      "Iteration #: 25\n",
      "Approximated Solution:  [0.10209841 0.14373773 0.16949425 0.18543697 0.19529767 0.20138236]\n",
      "Norm: 0.00019\n",
      "\n",
      "Iteration #: 26\n",
      "Approximated Solution:  [0.10221321 0.14387964 0.16961565 0.18552025 0.19534349 0.20139981]\n",
      "Norm: 0.00014\n",
      "\n",
      "Iteration #: 27\n",
      "Approximated Solution:  [0.1023011  0.14398829 0.16970859 0.18558401 0.19537856 0.20141316]\n",
      "Norm: 0.00011\n",
      "\n",
      "Iteration #: 28\n",
      "Approximated Solution:  [0.10236838 0.14407145 0.16977974 0.18563282 0.19540541 0.20142338]\n",
      "Norm: 0.00008\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[0.10236838 0.14407145 0.16977974 0.18563282 0.19540541 0.20142338]\n"
     ]
    }
   ],
   "source": [
    "# Reset Formatter\n",
    "#np.set_printoptions()\n",
    "\n",
    "# Gauss Seidel Function\n",
    "\n",
    "def gauss_seidel(A, b, min_tol=1e-4, max_tol = 1e4, iter_max=100):\n",
    "    norm = []\n",
    "    x = []\n",
    "    L = len(b)\n",
    "\n",
    "    xn = np.zeros(L)\n",
    "    x0 = np.zeros(L)\n",
    "    print('x0: ',x0)\n",
    "    print()\n",
    "\n",
    "    for itr in range(1,iter_max+1):\n",
    "        print(f'Iteration #: {itr}')\n",
    "        for i in range(0,L):\n",
    "            xn[i] = b[i]/A[i,i]\n",
    "            for j in range(0,L): \n",
    "                if (j<i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*xn[j])/A[i,i]\n",
    "                if (j>i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*x0[j])/A[i,i]\n",
    "        print('Approximated Solution: ', xn)\n",
    "        x.append(xn)\n",
    "    \n",
    "        #Stop condition \n",
    "        stop = np.linalg.norm(xn - x0, ord=np.inf)\n",
    "        norm.append(stop)\n",
    "        print(f'Norm: {stop:.5f}')\n",
    "        print()\n",
    "        \n",
    "        if stop <= min_tol:\n",
    "            print('Solution Converged!')\n",
    "            print('Best Approximated Solution: ')\n",
    "            break\n",
    "        elif stop >= max_tol:\n",
    "            print('Solution Diverged!')\n",
    "            print('Latest Approximated Solution: ')\n",
    "            break\n",
    "    \n",
    "        x0 = xn\n",
    "        xn = np.zeros(L)\n",
    "        \n",
    "    return xn, norm, x\n",
    "\n",
    "ans, error, x = gauss_seidel(A, b)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEYCAYAAACk+XocAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+8CVU8pg0N9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = range(1,len(error)+1)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(iteration,error, '-x');\n",
    "plt.xlabel('Iteration #')\n",
    "plt.ylabel(r'$|| x_{n+1} - x_{n} ||_{\\infty}$')\n",
    "plt.title(r'Plot of $|| x_{n+1} - x_{n} ||_{\\infty}$ vs Iteration Number')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Norm</th>\n",
       "      <th>Approximate Solution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.127136</td>\n",
       "      <td>[0.01319796954314721, 0.005024607694091578, 0.0019129217109485703, 0.0007282696869093543, 0.00027726003308731765, 0.12713601270295202]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078995</td>\n",
       "      <td>[0.01630965552629022, 0.007393911742170011, 0.0032659506724146805, 0.0014150864186180396, 0.07927271589419542, 0.15721042483281553]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049285</td>\n",
       "      <td>[0.017776940266724578, 0.008790439096644335, 0.004222961803653431, 0.05070047448916674, 0.11666095135173096, 0.1714445246262935]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034908</td>\n",
       "      <td>[0.018641794770510707, 0.009712365217431584, 0.03509586436033356, 0.08560825325855936, 0.13876574111065867, 0.179860053722332]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028980</td>\n",
       "      <td>[0.019212733789475397, 0.029048987239448473, 0.06407553776905014, 0.11033038450852345, 0.1533893674734201, 0.18542742416500765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.023878</td>\n",
       "      <td>[0.031187697681282815, 0.05155478646660065, 0.08795388779205539, 0.12847738282315435, 0.16374593634450513, 0.18937028033420247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020094</td>\n",
       "      <td>[0.045125299233123244, 0.07164858757926397, 0.1068420546846174, 0.14208202200698442, 0.17136713630099765, 0.19227175239885697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016435</td>\n",
       "      <td>[0.05756917606431576, 0.0880833445499848, 0.12152414987868507, 0.15239138004884817, 0.17708886952448813, 0.19445007723013508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012967</td>\n",
       "      <td>[0.06774704586344237, 0.10105063312161297, 0.13284541040649975, 0.16024491300748747, 0.18142780658699514, 0.19610195682246007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010068</td>\n",
       "      <td>[0.07577754944587199, 0.11111906740118462, 0.1415421799086412, 0.1662429233338147, 0.18473430447906716, 0.19736077581690376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007760</td>\n",
       "      <td>[0.08201282346672348, 0.11887871933430705, 0.14821086597359606, 0.1708294421038878, 0.18726001425103472, 0.19832234045090155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005959</td>\n",
       "      <td>[0.08681829319180437, 0.12483805907697486, 0.15332003232206814, 0.1743387013339155, 0.18919151337590684, 0.19905768275732494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004569</td>\n",
       "      <td>[0.09050884876848189, 0.12940714518237795, 0.15723277894119816, 0.17702448249974873, 0.1906694085475878, 0.19962033320339637]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003500</td>\n",
       "      <td>[0.09333843508756401, 0.13290752112890092, 0.16022868502353765, 0.17908030060695956, 0.19180052383927065, 0.20005096085251423]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002681</td>\n",
       "      <td>[0.09550618059759346, 0.13558813765325434, 0.16252237054844235, 0.18065401877931064, 0.19266633823581236, 0.20038058562277122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002052</td>\n",
       "      <td>[0.09716625783602553, 0.1376406017492989, 0.16427835239732647, 0.1818587294140538, 0.19332911752300572, 0.20063291276256562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001571</td>\n",
       "      <td>[0.09843732697164705, 0.13921197215912365, 0.16562265431699916, 0.18278097163239407, 0.19383648847442925, 0.2008260742922954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001203</td>\n",
       "      <td>[0.09941045991580245, 0.14041496609319332, 0.1666517817063024, 0.1834869808215891, 0.19422489657502146, 0.20097394539658175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000921</td>\n",
       "      <td>[0.1001554612353786, 0.1413359236589964, 0.1674396240338, 0.18402745779029245, 0.19452223691703, 0.20108714603440228]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>[0.1007258004385663, 0.14204096022850798, 0.1680427505967197, 0.18444121420625198, 0.1947498623434821, 0.20117380546071653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000540</td>\n",
       "      <td>[0.10116242207044657, 0.14258069658925532, 0.16850446892059334, 0.18475796129415895, 0.1949241185952758, 0.20124014667332835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000413</td>\n",
       "      <td>[0.10149667504512258, 0.14299388749592173, 0.16885793319838335, 0.18500044395178883, 0.19505751873365595, 0.20129093352804162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>[0.10175255976904798, 0.14331020219736734, 0.16912852450213597, 0.18518607422927016, 0.19515964191683421, 0.20132981291250035]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000242</td>\n",
       "      <td>[0.10194845009177064, 0.14355235404133698, 0.1693356731424936, 0.18532818172355733, 0.1952378213431058, 0.20135957665346668]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000185</td>\n",
       "      <td>[0.10209841214742696, 0.14373773113929564, 0.16949425383614805, 0.18543697076939092, 0.1952976708600368, 0.20138236200255208]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>[0.10221321420809172, 0.14387964484069513, 0.16961565379146104, 0.18552025319433535, 0.19534348809079444, 0.20139980511070854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>[0.10230109985058278, 0.14398828553985765, 0.16970859038171693, 0.1855840092675416, 0.19537856303843687, 0.2014131585171714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>[0.1023683798774753, 0.14407145440294472, 0.16977973711096916, 0.1856328171269644, 0.19540541433308245, 0.20142338109127506]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Error Norm  \\\n",
       "Iteration #               \n",
       "1            0.127136     \n",
       "2            0.078995     \n",
       "3            0.049285     \n",
       "4            0.034908     \n",
       "5            0.028980     \n",
       "6            0.023878     \n",
       "7            0.020094     \n",
       "8            0.016435     \n",
       "9            0.012967     \n",
       "10           0.010068     \n",
       "11           0.007760     \n",
       "12           0.005959     \n",
       "13           0.004569     \n",
       "14           0.003500     \n",
       "15           0.002681     \n",
       "16           0.002052     \n",
       "17           0.001571     \n",
       "18           0.001203     \n",
       "19           0.000921     \n",
       "20           0.000705     \n",
       "21           0.000540     \n",
       "22           0.000413     \n",
       "23           0.000316     \n",
       "24           0.000242     \n",
       "25           0.000185     \n",
       "26           0.000142     \n",
       "27           0.000109     \n",
       "28           0.000083     \n",
       "\n",
       "                                                                                                                               Approximate Solution  \n",
       "Iteration #                                                                                                                                          \n",
       "1            [0.01319796954314721, 0.005024607694091578, 0.0019129217109485703, 0.0007282696869093543, 0.00027726003308731765, 0.12713601270295202]  \n",
       "2            [0.01630965552629022, 0.007393911742170011, 0.0032659506724146805, 0.0014150864186180396, 0.07927271589419542, 0.15721042483281553]     \n",
       "3            [0.017776940266724578, 0.008790439096644335, 0.004222961803653431, 0.05070047448916674, 0.11666095135173096, 0.1714445246262935]        \n",
       "4            [0.018641794770510707, 0.009712365217431584, 0.03509586436033356, 0.08560825325855936, 0.13876574111065867, 0.179860053722332]          \n",
       "5            [0.019212733789475397, 0.029048987239448473, 0.06407553776905014, 0.11033038450852345, 0.1533893674734201, 0.18542742416500765]         \n",
       "6            [0.031187697681282815, 0.05155478646660065, 0.08795388779205539, 0.12847738282315435, 0.16374593634450513, 0.18937028033420247]         \n",
       "7            [0.045125299233123244, 0.07164858757926397, 0.1068420546846174, 0.14208202200698442, 0.17136713630099765, 0.19227175239885697]          \n",
       "8            [0.05756917606431576, 0.0880833445499848, 0.12152414987868507, 0.15239138004884817, 0.17708886952448813, 0.19445007723013508]           \n",
       "9            [0.06774704586344237, 0.10105063312161297, 0.13284541040649975, 0.16024491300748747, 0.18142780658699514, 0.19610195682246007]          \n",
       "10           [0.07577754944587199, 0.11111906740118462, 0.1415421799086412, 0.1662429233338147, 0.18473430447906716, 0.19736077581690376]            \n",
       "11           [0.08201282346672348, 0.11887871933430705, 0.14821086597359606, 0.1708294421038878, 0.18726001425103472, 0.19832234045090155]           \n",
       "12           [0.08681829319180437, 0.12483805907697486, 0.15332003232206814, 0.1743387013339155, 0.18919151337590684, 0.19905768275732494]           \n",
       "13           [0.09050884876848189, 0.12940714518237795, 0.15723277894119816, 0.17702448249974873, 0.1906694085475878, 0.19962033320339637]           \n",
       "14           [0.09333843508756401, 0.13290752112890092, 0.16022868502353765, 0.17908030060695956, 0.19180052383927065, 0.20005096085251423]          \n",
       "15           [0.09550618059759346, 0.13558813765325434, 0.16252237054844235, 0.18065401877931064, 0.19266633823581236, 0.20038058562277122]          \n",
       "16           [0.09716625783602553, 0.1376406017492989, 0.16427835239732647, 0.1818587294140538, 0.19332911752300572, 0.20063291276256562]            \n",
       "17           [0.09843732697164705, 0.13921197215912365, 0.16562265431699916, 0.18278097163239407, 0.19383648847442925, 0.2008260742922954]           \n",
       "18           [0.09941045991580245, 0.14041496609319332, 0.1666517817063024, 0.1834869808215891, 0.19422489657502146, 0.20097394539658175]            \n",
       "19           [0.1001554612353786, 0.1413359236589964, 0.1674396240338, 0.18402745779029245, 0.19452223691703, 0.20108714603440228]                   \n",
       "20           [0.1007258004385663, 0.14204096022850798, 0.1680427505967197, 0.18444121420625198, 0.1947498623434821, 0.20117380546071653]             \n",
       "21           [0.10116242207044657, 0.14258069658925532, 0.16850446892059334, 0.18475796129415895, 0.1949241185952758, 0.20124014667332835]           \n",
       "22           [0.10149667504512258, 0.14299388749592173, 0.16885793319838335, 0.18500044395178883, 0.19505751873365595, 0.20129093352804162]          \n",
       "23           [0.10175255976904798, 0.14331020219736734, 0.16912852450213597, 0.18518607422927016, 0.19515964191683421, 0.20132981291250035]          \n",
       "24           [0.10194845009177064, 0.14355235404133698, 0.1693356731424936, 0.18532818172355733, 0.1952378213431058, 0.20135957665346668]            \n",
       "25           [0.10209841214742696, 0.14373773113929564, 0.16949425383614805, 0.18543697076939092, 0.1952976708600368, 0.20138236200255208]           \n",
       "26           [0.10221321420809172, 0.14387964484069513, 0.16961565379146104, 0.18552025319433535, 0.19534348809079444, 0.20139980511070854]          \n",
       "27           [0.10230109985058278, 0.14398828553985765, 0.16970859038171693, 0.1855840092675416, 0.19537856303843687, 0.2014131585171714]            \n",
       "28           [0.1023683798774753, 0.14407145440294472, 0.16977973711096916, 0.1856328171269644, 0.19540541433308245, 0.20142338109127506]            "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "df = pd.DataFrame(list(zip(error, x)), index =[*range(1, len(error)+1)], \n",
    "                  columns =['Error Norm','Approximate Solution'])\n",
    "df.index.names = ['Iteration #']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gauss Seidel method takes 28 iterations to converge for the given system of equations.\n",
    "* Error norm is consistently decreasing and at iteration 28 meets the convergence criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pagebreak$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-78.8,  48.8,   0. ,   0. ,   0. ,   0. ],\n",
       "        [ 30. , -78.8,  48.8,   0. ,   0. ,   0. ],\n",
       "        [  0. ,  30. , -78.8,  48.8,   0. ,   0. ],\n",
       "        [  0. ,   0. ,  30. , -78.8,  48.8,   0. ],\n",
       "        [  0. ,   0. ,   0. ,  30. , -78.8,  48.8],\n",
       "        [  0. ,   0. ,   0. ,   0. ,  30. , -78.8]]),\n",
       " array([ -1.04,   0.  ,   0.  ,   0.  ,   0.  , -10.01]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to iteratively solve Ax = b for x, with Jacobi method in double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:  [1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [0.63248731 1.         1.         1.         1.         0.50774112]\n",
      "Error Norm: 0.49226\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [0.63248731 0.860084   1.         1.         0.69514932 0.50774112]\n",
      "Error Norm: 0.30485\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [0.54583882 0.860084   0.94673249 0.81120922 0.69514932 0.39168121]\n",
      "Error Norm: 0.18879\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [0.54583882 0.794108   0.82981637 0.79092971 0.5514     0.39168121]\n",
      "Error Norm: 0.14375\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [0.50498059 0.72170309 0.79213972 0.65739608 0.54367937 0.33695431]\n",
      "Error Norm: 0.13353\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [0.460141   0.68281518 0.68187845 0.63827088 0.45894991 0.33401499]\n",
      "Error Norm: 0.11026\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [0.43605813 0.59746064 0.65522937 0.54382118 0.44984845 0.30175758]\n",
      "Error Norm: 0.09445\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [0.38319897 0.57178854 0.56424229 0.52803915 0.39391377 0.29829256]\n",
      "Error Norm: 0.09099\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [0.36730052 0.49531717 0.54469501 0.45875966 0.38575954 0.27699763]\n",
      "Error Norm: 0.07647\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [0.31994261 0.47715904 0.47267749 0.44626797 0.34619637 0.27389322]\n",
      "Error Norm: 0.07202\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [0.30869747 0.4145297  0.45802853 0.39434908 0.33951813 0.25883111]\n",
      "Error Norm: 0.06263\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [0.26991179 0.4011766  0.40203206 0.3846363  0.31042424 0.25628863]\n",
      "Error Norm: 0.05600\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [0.26164236 0.35173246 0.39093337 0.34530031 0.30515195 0.24521228]\n",
      "Error Norm: 0.04944\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [0.23102213 0.3417109  0.3477491  0.33780985 0.28331686 0.24320506]\n",
      "Error Norm: 0.04318\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [0.22481589 0.3033099  0.33929502 0.3078469  0.27922211 0.23489221]\n",
      "Error Norm: 0.03840\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [0.20103456 0.2957116  0.30611962 0.30209251 0.26266684 0.23333329]\n",
      "Error Norm: 0.03318\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [0.19632901 0.26611261 0.29966323 0.27920977 0.25951066 0.22703052]\n",
      "Error Norm: 0.02960\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [0.17799868 0.26032279 0.27422354 0.27479717 0.24689572 0.22582893]\n",
      "Error Norm: 0.02544\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [0.1744131  0.23758971 0.26928662 0.25729971 0.24447166 0.22102629]\n",
      "Error Norm: 0.02273\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [0.16033475 0.23316726 0.24979591 0.25391898 0.23483597 0.22010342]\n",
      "Error Norm: 0.01949\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [0.15759597 0.21573709 0.24601858 0.24053138 0.23297737 0.21643501]\n",
      "Error Norm: 0.01743\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [0.14680165 0.21235515 0.23109193 0.2379423  0.22560876 0.21572742]\n",
      "Error Norm: 0.01493\n",
      "\n",
      "Iteration #: 23\n",
      "Approximated Solution:  [0.14470725 0.19900172 0.228201   0.22769626 0.22418486 0.21292211]\n",
      "Error Norm: 0.01335\n",
      "\n",
      "Iteration #: 24\n",
      "Approximated Solution:  [0.13643761 0.19641404 0.21677194 0.22571385 0.21854679 0.21238002]\n",
      "Error Norm: 0.01143\n",
      "\n",
      "Iteration #: 25\n",
      "Approximated Solution:  [0.13483509 0.18618781 0.2145591  0.21787108 0.21745635 0.21023355]\n",
      "Error Norm: 0.01023\n",
      "\n",
      "Iteration #: 26\n",
      "Approximated Solution:  [0.12850209 0.18420732 0.20580892 0.21635334 0.21314124 0.20981841]\n",
      "Error Norm: 0.00875\n",
      "\n",
      "Iteration #: 27\n",
      "Approximated Solution:  [0.1272756  0.17637739 0.204115   0.21034975 0.21230633 0.2081756 ]\n",
      "Error Norm: 0.00783\n",
      "\n",
      "Iteration #: 28\n",
      "Approximated Solution:  [0.12242661 0.17486142 0.19741611 0.2091878  0.20900332 0.20785774]\n",
      "Error Norm: 0.00670\n",
      "\n",
      "Iteration #: 29\n",
      "Approximated Solution:  [0.12148778 0.16886681 0.19611938 0.20459195 0.20836411 0.20660025]\n",
      "Error Norm: 0.00599\n",
      "\n",
      "Iteration #: 30\n",
      "Approximated Solution:  [0.11777538 0.16770634 0.190991   0.20370241 0.20583567 0.20635689]\n",
      "Error Norm: 0.00513\n",
      "\n",
      "Iteration #: 31\n",
      "Approximated Solution:  [0.11705672 0.16311704 0.18999832 0.20018415 0.2053463  0.20539429]\n",
      "Error Norm: 0.00459\n",
      "\n",
      "Iteration #: 32\n",
      "Approximated Solution:  [0.11421461 0.16222868 0.1860723  0.19950316 0.20341073 0.20520798]\n",
      "Error Norm: 0.00393\n",
      "\n",
      "Iteration #: 33\n",
      "Approximated Solution:  [0.11366446 0.15871531 0.18531237 0.19680981 0.2030361  0.20447109]\n",
      "Error Norm: 0.00351\n",
      "\n",
      "Iteration #: 34\n",
      "Approximated Solution:  [0.11148867 0.15803525 0.18230683 0.19628849 0.20155436 0.20432846]\n",
      "Error Norm: 0.00301\n",
      "\n",
      "Iteration #: 35\n",
      "Approximated Solution:  [0.11106751 0.1553456  0.18172507 0.19422662 0.20126756 0.20376435]\n",
      "Error Norm: 0.00269\n",
      "\n",
      "Iteration #: 36\n",
      "Approximated Solution:  [0.10940184 0.15482498 0.1794242  0.19382752 0.20013323 0.20365516]\n",
      "Error Norm: 0.00230\n",
      "\n",
      "Iteration #: 37\n",
      "Approximated Solution:  [0.10907943 0.15276594 0.17897884 0.19224908 0.19991368 0.20322331]\n",
      "Error Norm: 0.00206\n",
      "\n",
      "Iteration #: 38\n",
      "Approximated Solution:  [0.10780429 0.15236739 0.17721743 0.19194356 0.19904531 0.20313972]\n",
      "Error Norm: 0.00176\n",
      "\n",
      "Iteration #: 39\n",
      "Approximated Solution:  [0.10755747 0.15079111 0.17687649 0.1907352  0.19887723 0.20280913]\n",
      "Error Norm: 0.00158\n",
      "\n",
      "Iteration #: 40\n",
      "Approximated Solution:  [0.1065813  0.150486   0.17552806 0.19050131 0.19821245 0.20274514]\n",
      "Error Norm: 0.00135\n",
      "\n",
      "Iteration #: 41\n",
      "Approximated Solution:  [0.10639235 0.14927929 0.17526706 0.18957626 0.19808378 0.20249205]\n",
      "Error Norm: 0.00121\n",
      "\n",
      "Iteration #: 42\n",
      "Approximated Solution:  [0.10564504 0.14904572 0.17423478 0.18939721 0.19757487 0.20244306]\n",
      "Error Norm: 0.00103\n",
      "\n",
      "Iteration #: 43\n",
      "Approximated Solution:  [0.10550039 0.14812193 0.17403497 0.18868905 0.19747637 0.20224932]\n",
      "Error Norm: 0.00092\n",
      "\n",
      "Iteration #: 44\n",
      "Approximated Solution:  [0.1049283  0.14794313 0.17324472 0.18855198 0.19708678 0.20221182]\n",
      "Error Norm: 0.00079\n",
      "\n",
      "Iteration #: 45\n",
      "Approximated Solution:  [0.10481757 0.14723593 0.17309175 0.18800985 0.19701137 0.20206349]\n",
      "Error Norm: 0.00071\n",
      "\n",
      "Iteration #: 46\n",
      "Approximated Solution:  [0.10437961 0.14709904 0.17248678 0.18790492 0.19671312 0.20203479]\n",
      "Error Norm: 0.00060\n",
      "\n",
      "Iteration #: 47\n",
      "Approximated Solution:  [0.10429484 0.14655766 0.17236969 0.1874899  0.19665539 0.20192124]\n",
      "Error Norm: 0.00054\n",
      "\n",
      "Iteration #: 48\n",
      "Approximated Solution:  [0.10395956 0.14645287 0.17190656 0.18740957 0.19642707 0.20189926]\n",
      "Error Norm: 0.00046\n",
      "\n",
      "Iteration #: 49\n",
      "Approximated Solution:  [0.10389467 0.14603841 0.17181691 0.18709185 0.19638288 0.20181234]\n",
      "Error Norm: 0.00041\n",
      "\n",
      "Iteration #: 50\n",
      "Approximated Solution:  [0.103638   0.14595819 0.17146237 0.18703036 0.19620809 0.20179551]\n",
      "Error Norm: 0.00035\n",
      "\n",
      "Iteration #: 51\n",
      "Approximated Solution:  [0.10358832 0.14564091 0.17139374 0.18678713 0.19617426 0.20172897]\n",
      "Error Norm: 0.00032\n",
      "\n",
      "Iteration #: 52\n",
      "Approximated Solution:  [0.10339183 0.1455795  0.17112233 0.18674005 0.19604045 0.20171609]\n",
      "Error Norm: 0.00027\n",
      "\n",
      "Iteration #: 53\n",
      "Approximated Solution:  [0.1033538  0.14533661 0.17106979 0.18655386 0.19601455 0.20166515]\n",
      "Error Norm: 0.00024\n",
      "\n",
      "Iteration #: 54\n",
      "Approximated Solution:  [0.10320338 0.14528959 0.17086201 0.18651782 0.19591212 0.20165529]\n",
      "Error Norm: 0.00021\n",
      "\n",
      "Iteration #: 55\n",
      "Approximated Solution:  [0.10317426 0.14510365 0.17082179 0.18637527 0.19589229 0.20161629]\n",
      "Error Norm: 0.00019\n",
      "\n",
      "Iteration #: 56\n",
      "Approximated Solution:  [0.10305911 0.14506766 0.17066273 0.18634768 0.19581387 0.20160874]\n",
      "Error Norm: 0.00016\n",
      "\n",
      "Iteration #: 57\n",
      "Approximated Solution:  [0.10303682 0.14492531 0.17063194 0.18623856 0.19579869 0.20157889]\n",
      "Error Norm: 0.00014\n",
      "\n",
      "Iteration #: 58\n",
      "Approximated Solution:  [0.10294867 0.14489776 0.17051017 0.18621744 0.19573866 0.20157311]\n",
      "Error Norm: 0.00012\n",
      "\n",
      "Iteration #: 59\n",
      "Approximated Solution:  [0.10293161 0.14478878 0.1704866  0.1861339  0.19572704 0.20155025]\n",
      "Error Norm: 0.00011\n",
      "\n",
      "Iteration #: 60\n",
      "Approximated Solution:  [0.10286412 0.14476769 0.17039338 0.18611773 0.19568108 0.20154583]\n",
      "Error Norm: 0.00009\n",
      "\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[0.10286412 0.14476769 0.17039338 0.18611773 0.19568108 0.20154583]\n"
     ]
    }
   ],
   "source": [
    "# Print upto 5 decimal places\n",
    "#np.set_printoptions(precision=5)\n",
    "\n",
    "def jacobi_method(A, b, min_tol=1e-4, max_tol = 1e4, iter_max=100):\n",
    "    \n",
    "    norm = [] # List to store norm values\n",
    "    x = []\n",
    "    L = len(b)\n",
    "    xn = np.zeros(L) # Initialize approximated solution\n",
    "\n",
    "    x0 = np.ones(L) # Initialize first approximation with vector 1\n",
    "    print('x0: ',x0)\n",
    "    print()\n",
    "\n",
    "    for itr in range(1,iter_max+1): # Start Loop\n",
    "        print(f'Iteration #: {itr}')\n",
    "        for i in range(0,L):\n",
    "            xn[i] = b[i]/A[i,i]\n",
    "            for j in range(0,L): \n",
    "                if (i != j):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*x0[j])/A[i,i]\n",
    "        \n",
    "        print('Approximated Solution: ', xn)\n",
    "        x.append(xn)\n",
    "    \n",
    "        #Stop condition \n",
    "        stop = np.linalg.norm(xn - x0, ord=np.inf)\n",
    "        norm.append(stop)\n",
    "        print(f'Error Norm: {stop:.5f}')\n",
    "        print()\n",
    "        \n",
    "        if stop <= min_tol:\n",
    "            print()\n",
    "            print('Solution Converged!')\n",
    "            print('Best Approximated Solution: ')\n",
    "            #print(xn)\n",
    "            break\n",
    "        elif stop >= max_tol:\n",
    "            print()\n",
    "            print('Solution Diverged!')\n",
    "            print('Latest Approximated Solution: ')\n",
    "            #print(xn)\n",
    "            break\n",
    "    \n",
    "        x0 = xn\n",
    "        xn = np.zeros([L])\n",
    "    \n",
    "    return xn, norm, x\n",
    "\n",
    "ans, error, approx = jacobi_method(A, b)\n",
    "print(ans)\n",
    "\n",
    "# Reset Formatter\n",
    "#np.set_printoptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Norm</th>\n",
       "      <th>Approximate Solution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49226</td>\n",
       "      <td>[0.63249, 1.0, 1.0, 1.0, 1.0, 0.50774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30485</td>\n",
       "      <td>[0.63249, 0.86008, 1.0, 1.0, 0.69515, 0.50774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.18879</td>\n",
       "      <td>[0.54584, 0.86008, 0.94673, 0.81121, 0.69515, 0.39168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14375</td>\n",
       "      <td>[0.54584, 0.79411, 0.82982, 0.79093, 0.5514, 0.39168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.13353</td>\n",
       "      <td>[0.50498, 0.7217, 0.79214, 0.6574, 0.54368, 0.33695]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.11026</td>\n",
       "      <td>[0.46014, 0.68282, 0.68188, 0.63827, 0.45895, 0.33401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.09445</td>\n",
       "      <td>[0.43606, 0.59746, 0.65523, 0.54382, 0.44985, 0.30176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09099</td>\n",
       "      <td>[0.3832, 0.57179, 0.56424, 0.52804, 0.39391, 0.29829]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.07647</td>\n",
       "      <td>[0.3673, 0.49532, 0.5447, 0.45876, 0.38576, 0.277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.07202</td>\n",
       "      <td>[0.31994, 0.47716, 0.47268, 0.44627, 0.3462, 0.27389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>[0.3087, 0.41453, 0.45803, 0.39435, 0.33952, 0.25883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.05600</td>\n",
       "      <td>[0.26991, 0.40118, 0.40203, 0.38464, 0.31042, 0.25629]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.04944</td>\n",
       "      <td>[0.26164, 0.35173, 0.39093, 0.3453, 0.30515, 0.24521]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.04318</td>\n",
       "      <td>[0.23102, 0.34171, 0.34775, 0.33781, 0.28332, 0.24321]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.03840</td>\n",
       "      <td>[0.22482, 0.30331, 0.3393, 0.30785, 0.27922, 0.23489]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.03318</td>\n",
       "      <td>[0.20103, 0.29571, 0.30612, 0.30209, 0.26267, 0.23333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.02960</td>\n",
       "      <td>[0.19633, 0.26611, 0.29966, 0.27921, 0.25951, 0.22703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.02544</td>\n",
       "      <td>[0.178, 0.26032, 0.27422, 0.2748, 0.2469, 0.22583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.02273</td>\n",
       "      <td>[0.17441, 0.23759, 0.26929, 0.2573, 0.24447, 0.22103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01949</td>\n",
       "      <td>[0.16033, 0.23317, 0.2498, 0.25392, 0.23484, 0.2201]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.01743</td>\n",
       "      <td>[0.1576, 0.21574, 0.24602, 0.24053, 0.23298, 0.21644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.01493</td>\n",
       "      <td>[0.1468, 0.21236, 0.23109, 0.23794, 0.22561, 0.21573]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.01335</td>\n",
       "      <td>[0.14471, 0.199, 0.2282, 0.2277, 0.22418, 0.21292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01143</td>\n",
       "      <td>[0.13644, 0.19641, 0.21677, 0.22571, 0.21855, 0.21238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01023</td>\n",
       "      <td>[0.13484, 0.18619, 0.21456, 0.21787, 0.21746, 0.21023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.00875</td>\n",
       "      <td>[0.1285, 0.18421, 0.20581, 0.21635, 0.21314, 0.20982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.00783</td>\n",
       "      <td>[0.12728, 0.17638, 0.20412, 0.21035, 0.21231, 0.20818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.00670</td>\n",
       "      <td>[0.12243, 0.17486, 0.19742, 0.20919, 0.209, 0.20786]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.00599</td>\n",
       "      <td>[0.12149, 0.16887, 0.19612, 0.20459, 0.20836, 0.2066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.00513</td>\n",
       "      <td>[0.11778, 0.16771, 0.19099, 0.2037, 0.20584, 0.20636]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.00459</td>\n",
       "      <td>[0.11706, 0.16312, 0.19, 0.20018, 0.20535, 0.20539]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.00393</td>\n",
       "      <td>[0.11421, 0.16223, 0.18607, 0.1995, 0.20341, 0.20521]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.00351</td>\n",
       "      <td>[0.11366, 0.15872, 0.18531, 0.19681, 0.20304, 0.20447]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.00301</td>\n",
       "      <td>[0.11149, 0.15804, 0.18231, 0.19629, 0.20155, 0.20433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.00269</td>\n",
       "      <td>[0.11107, 0.15535, 0.18173, 0.19423, 0.20127, 0.20376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.00230</td>\n",
       "      <td>[0.1094, 0.15482, 0.17942, 0.19383, 0.20013, 0.20366]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.00206</td>\n",
       "      <td>[0.10908, 0.15277, 0.17898, 0.19225, 0.19991, 0.20322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.00176</td>\n",
       "      <td>[0.1078, 0.15237, 0.17722, 0.19194, 0.19905, 0.20314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.00158</td>\n",
       "      <td>[0.10756, 0.15079, 0.17688, 0.19074, 0.19888, 0.20281]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.00135</td>\n",
       "      <td>[0.10658, 0.15049, 0.17553, 0.1905, 0.19821, 0.20275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.00121</td>\n",
       "      <td>[0.10639, 0.14928, 0.17527, 0.18958, 0.19808, 0.20249]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.00103</td>\n",
       "      <td>[0.10565, 0.14905, 0.17423, 0.1894, 0.19757, 0.20244]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.00092</td>\n",
       "      <td>[0.1055, 0.14812, 0.17403, 0.18869, 0.19748, 0.20225]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.00079</td>\n",
       "      <td>[0.10493, 0.14794, 0.17324, 0.18855, 0.19709, 0.20221]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.00071</td>\n",
       "      <td>[0.10482, 0.14724, 0.17309, 0.18801, 0.19701, 0.20206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.00060</td>\n",
       "      <td>[0.10438, 0.1471, 0.17249, 0.1879, 0.19671, 0.20203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00054</td>\n",
       "      <td>[0.10429, 0.14656, 0.17237, 0.18749, 0.19666, 0.20192]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.00046</td>\n",
       "      <td>[0.10396, 0.14645, 0.17191, 0.18741, 0.19643, 0.2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00041</td>\n",
       "      <td>[0.10389, 0.14604, 0.17182, 0.18709, 0.19638, 0.20181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>[0.10364, 0.14596, 0.17146, 0.18703, 0.19621, 0.2018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.00032</td>\n",
       "      <td>[0.10359, 0.14564, 0.17139, 0.18679, 0.19617, 0.20173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.00027</td>\n",
       "      <td>[0.10339, 0.14558, 0.17112, 0.18674, 0.19604, 0.20172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00024</td>\n",
       "      <td>[0.10335, 0.14534, 0.17107, 0.18655, 0.19601, 0.20167]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00021</td>\n",
       "      <td>[0.1032, 0.14529, 0.17086, 0.18652, 0.19591, 0.20166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00019</td>\n",
       "      <td>[0.10317, 0.1451, 0.17082, 0.18638, 0.19589, 0.20162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00016</td>\n",
       "      <td>[0.10306, 0.14507, 0.17066, 0.18635, 0.19581, 0.20161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.00014</td>\n",
       "      <td>[0.10304, 0.14493, 0.17063, 0.18624, 0.1958, 0.20158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>[0.10295, 0.1449, 0.17051, 0.18622, 0.19574, 0.20157]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.00011</td>\n",
       "      <td>[0.10293, 0.14479, 0.17049, 0.18613, 0.19573, 0.20155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>[0.10286, 0.14477, 0.17039, 0.18612, 0.19568, 0.20155]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Error Norm  \\\n",
       "Iteration #               \n",
       "1            0.49226      \n",
       "2            0.30485      \n",
       "3            0.18879      \n",
       "4            0.14375      \n",
       "5            0.13353      \n",
       "6            0.11026      \n",
       "7            0.09445      \n",
       "8            0.09099      \n",
       "9            0.07647      \n",
       "10           0.07202      \n",
       "11           0.06263      \n",
       "12           0.05600      \n",
       "13           0.04944      \n",
       "14           0.04318      \n",
       "15           0.03840      \n",
       "16           0.03318      \n",
       "17           0.02960      \n",
       "18           0.02544      \n",
       "19           0.02273      \n",
       "20           0.01949      \n",
       "21           0.01743      \n",
       "22           0.01493      \n",
       "23           0.01335      \n",
       "24           0.01143      \n",
       "25           0.01023      \n",
       "26           0.00875      \n",
       "27           0.00783      \n",
       "28           0.00670      \n",
       "29           0.00599      \n",
       "30           0.00513      \n",
       "31           0.00459      \n",
       "32           0.00393      \n",
       "33           0.00351      \n",
       "34           0.00301      \n",
       "35           0.00269      \n",
       "36           0.00230      \n",
       "37           0.00206      \n",
       "38           0.00176      \n",
       "39           0.00158      \n",
       "40           0.00135      \n",
       "41           0.00121      \n",
       "42           0.00103      \n",
       "43           0.00092      \n",
       "44           0.00079      \n",
       "45           0.00071      \n",
       "46           0.00060      \n",
       "47           0.00054      \n",
       "48           0.00046      \n",
       "49           0.00041      \n",
       "50           0.00035      \n",
       "51           0.00032      \n",
       "52           0.00027      \n",
       "53           0.00024      \n",
       "54           0.00021      \n",
       "55           0.00019      \n",
       "56           0.00016      \n",
       "57           0.00014      \n",
       "58           0.00012      \n",
       "59           0.00011      \n",
       "60           0.00009      \n",
       "\n",
       "                                               Approximate Solution  \n",
       "Iteration #                                                          \n",
       "1            [0.63249, 1.0, 1.0, 1.0, 1.0, 0.50774]                  \n",
       "2            [0.63249, 0.86008, 1.0, 1.0, 0.69515, 0.50774]          \n",
       "3            [0.54584, 0.86008, 0.94673, 0.81121, 0.69515, 0.39168]  \n",
       "4            [0.54584, 0.79411, 0.82982, 0.79093, 0.5514, 0.39168]   \n",
       "5            [0.50498, 0.7217, 0.79214, 0.6574, 0.54368, 0.33695]    \n",
       "6            [0.46014, 0.68282, 0.68188, 0.63827, 0.45895, 0.33401]  \n",
       "7            [0.43606, 0.59746, 0.65523, 0.54382, 0.44985, 0.30176]  \n",
       "8            [0.3832, 0.57179, 0.56424, 0.52804, 0.39391, 0.29829]   \n",
       "9            [0.3673, 0.49532, 0.5447, 0.45876, 0.38576, 0.277]      \n",
       "10           [0.31994, 0.47716, 0.47268, 0.44627, 0.3462, 0.27389]   \n",
       "11           [0.3087, 0.41453, 0.45803, 0.39435, 0.33952, 0.25883]   \n",
       "12           [0.26991, 0.40118, 0.40203, 0.38464, 0.31042, 0.25629]  \n",
       "13           [0.26164, 0.35173, 0.39093, 0.3453, 0.30515, 0.24521]   \n",
       "14           [0.23102, 0.34171, 0.34775, 0.33781, 0.28332, 0.24321]  \n",
       "15           [0.22482, 0.30331, 0.3393, 0.30785, 0.27922, 0.23489]   \n",
       "16           [0.20103, 0.29571, 0.30612, 0.30209, 0.26267, 0.23333]  \n",
       "17           [0.19633, 0.26611, 0.29966, 0.27921, 0.25951, 0.22703]  \n",
       "18           [0.178, 0.26032, 0.27422, 0.2748, 0.2469, 0.22583]      \n",
       "19           [0.17441, 0.23759, 0.26929, 0.2573, 0.24447, 0.22103]   \n",
       "20           [0.16033, 0.23317, 0.2498, 0.25392, 0.23484, 0.2201]    \n",
       "21           [0.1576, 0.21574, 0.24602, 0.24053, 0.23298, 0.21644]   \n",
       "22           [0.1468, 0.21236, 0.23109, 0.23794, 0.22561, 0.21573]   \n",
       "23           [0.14471, 0.199, 0.2282, 0.2277, 0.22418, 0.21292]      \n",
       "24           [0.13644, 0.19641, 0.21677, 0.22571, 0.21855, 0.21238]  \n",
       "25           [0.13484, 0.18619, 0.21456, 0.21787, 0.21746, 0.21023]  \n",
       "26           [0.1285, 0.18421, 0.20581, 0.21635, 0.21314, 0.20982]   \n",
       "27           [0.12728, 0.17638, 0.20412, 0.21035, 0.21231, 0.20818]  \n",
       "28           [0.12243, 0.17486, 0.19742, 0.20919, 0.209, 0.20786]    \n",
       "29           [0.12149, 0.16887, 0.19612, 0.20459, 0.20836, 0.2066]   \n",
       "30           [0.11778, 0.16771, 0.19099, 0.2037, 0.20584, 0.20636]   \n",
       "31           [0.11706, 0.16312, 0.19, 0.20018, 0.20535, 0.20539]     \n",
       "32           [0.11421, 0.16223, 0.18607, 0.1995, 0.20341, 0.20521]   \n",
       "33           [0.11366, 0.15872, 0.18531, 0.19681, 0.20304, 0.20447]  \n",
       "34           [0.11149, 0.15804, 0.18231, 0.19629, 0.20155, 0.20433]  \n",
       "35           [0.11107, 0.15535, 0.18173, 0.19423, 0.20127, 0.20376]  \n",
       "36           [0.1094, 0.15482, 0.17942, 0.19383, 0.20013, 0.20366]   \n",
       "37           [0.10908, 0.15277, 0.17898, 0.19225, 0.19991, 0.20322]  \n",
       "38           [0.1078, 0.15237, 0.17722, 0.19194, 0.19905, 0.20314]   \n",
       "39           [0.10756, 0.15079, 0.17688, 0.19074, 0.19888, 0.20281]  \n",
       "40           [0.10658, 0.15049, 0.17553, 0.1905, 0.19821, 0.20275]   \n",
       "41           [0.10639, 0.14928, 0.17527, 0.18958, 0.19808, 0.20249]  \n",
       "42           [0.10565, 0.14905, 0.17423, 0.1894, 0.19757, 0.20244]   \n",
       "43           [0.1055, 0.14812, 0.17403, 0.18869, 0.19748, 0.20225]   \n",
       "44           [0.10493, 0.14794, 0.17324, 0.18855, 0.19709, 0.20221]  \n",
       "45           [0.10482, 0.14724, 0.17309, 0.18801, 0.19701, 0.20206]  \n",
       "46           [0.10438, 0.1471, 0.17249, 0.1879, 0.19671, 0.20203]    \n",
       "47           [0.10429, 0.14656, 0.17237, 0.18749, 0.19666, 0.20192]  \n",
       "48           [0.10396, 0.14645, 0.17191, 0.18741, 0.19643, 0.2019]   \n",
       "49           [0.10389, 0.14604, 0.17182, 0.18709, 0.19638, 0.20181]  \n",
       "50           [0.10364, 0.14596, 0.17146, 0.18703, 0.19621, 0.2018]   \n",
       "51           [0.10359, 0.14564, 0.17139, 0.18679, 0.19617, 0.20173]  \n",
       "52           [0.10339, 0.14558, 0.17112, 0.18674, 0.19604, 0.20172]  \n",
       "53           [0.10335, 0.14534, 0.17107, 0.18655, 0.19601, 0.20167]  \n",
       "54           [0.1032, 0.14529, 0.17086, 0.18652, 0.19591, 0.20166]   \n",
       "55           [0.10317, 0.1451, 0.17082, 0.18638, 0.19589, 0.20162]   \n",
       "56           [0.10306, 0.14507, 0.17066, 0.18635, 0.19581, 0.20161]  \n",
       "57           [0.10304, 0.14493, 0.17063, 0.18624, 0.1958, 0.20158]   \n",
       "58           [0.10295, 0.1449, 0.17051, 0.18622, 0.19574, 0.20157]   \n",
       "59           [0.10293, 0.14479, 0.17049, 0.18613, 0.19573, 0.20155]  \n",
       "60           [0.10286, 0.14477, 0.17039, 0.18612, 0.19568, 0.20155]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "df = pd.DataFrame(list(zip(np.around(error,5), np.around(approx,5))), \n",
    "                  index =[*range(1, len(error)+1)], \n",
    "                  columns =['Error Norm','Approximate Solution'])\n",
    "df.index.names = ['Iteration #']\n",
    "#df.round(5)\n",
    "#pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Jacobi method takes 60 iterations to converge for the given system of equations.\n",
    "* It is higher than the number of iterations taken for Gauss Seidel method.\n",
    "* Error norm is consistently decreasing but the rate is slower than Gauss Seidel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pagebreak$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7., -3.,  0.,  0.,  0.],\n",
       "       [-3.,  9.,  2.,  0.,  0.],\n",
       "       [ 0.,  1.,  3., -1.,  0.],\n",
       "       [ 0.,  0., -1., 10., -4.],\n",
       "       [ 0.,  0.,  0., -4.,  6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[7,-3,0,0,0],\n",
    "              [-3,9,2,0,0],\n",
    "              [0,1,3,-1,0],\n",
    "              [0,0,-1,10,-4],\n",
    "              [0,0,0,-4,6]], float)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8., -12.,   5.,  14.,   5.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([8,-12,5,14,5],float)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30510666, -1.95475113,  3.25404008,  2.8073691 ,  2.70491273])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the solution using library for verification\n",
    "np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to iteratively solve Ax = b for x, with SOR (successive over-relaxation) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relaxation Parameter: 1.1\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.25714286 -1.00571429  2.20209524  1.78223048  2.22363568]\n",
      "Norm: 2.223635682539683\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.65730612 -1.66337294  2.87651173  2.65659294  2.64247126]\n",
      "Norm: 0.8743624666868226\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.40725072 -1.85415142  3.19962176  2.78898645  2.69767627]\n",
      "Norm: 0.323110031870387\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.34231783 -1.93786475  3.24654993  2.80519941  2.70404527]\n",
      "Norm: 0.08371332906561824\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.30934626 -1.95305432  3.25337137  2.80713083  2.70482475]\n",
      "Norm: 0.032971566503651295\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.30548262 -1.9546195   3.25397132  2.80734665  2.70490507]\n",
      "Norm: 0.0038636416469324253\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.30513112 -1.95473852  3.2540341   2.80736732  2.70491219]\n",
      "Norm: 0.0003515041425992127\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30511016 -1.95474965  3.25403948  2.80736898  2.7049127 ]\n",
      "Norm: 2.0958882837374126e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30511016 -1.95474965  3.25403948  2.80736898  2.7049127 ]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.2000000000000002\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.37142857 -1.05142857  2.42057143  1.97046857  2.57637486]\n",
      "Norm: 2.576374857142858\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.55640816 -1.81263673  3.02912784  2.88606156  2.79357427]\n",
      "Norm: 0.9155929861224492\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.32793376 -1.91406657  3.31422568  2.84141042  2.71441348]\n",
      "Norm: 0.2850978476656949\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.32146473 -1.97239431  3.26267676  2.8061576   2.70204338]\n",
      "Norm: 0.058327739593539984\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.29276141 -1.95846371  3.25331317  2.80614688  2.70450883]\n",
      "Norm: 0.028703316065849083\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.30566638 -1.95359088  3.25323247  2.80732276  2.70495644]\n",
      "Norm: 0.012904972928345915\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.30559141 -1.95457392  3.25411218  2.807408    2.70493511]\n",
      "Norm: 0.0009830335381255662\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30510085 -1.95480813  3.25406402  2.80737494  2.70491293]\n",
      "Norm: 0.0004905660185257066\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.30507851 -1.95475738  3.25404012  2.80736803  2.70491184]\n",
      "Norm: 5.074985246467101e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30507851 -1.95475738  3.25404012  2.80736803  2.70491184]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.3000000000000003\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.48571429 -1.08952381  2.63879365  2.16304317  2.95797075]\n",
      "Norm: 2.9579707513227524\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.43297959 -1.98116987  3.17085422  3.12144289  2.90119261]\n",
      "Norm: 1.0527346938775515\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.25202577 -1.94579576  3.41121381  2.83564509  2.67053463]\n",
      "Norm: 0.2857978003020447\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.32602035 -1.99378089  3.23605378  2.77867147  2.69035489]\n",
      "Norm: 0.1751600344608888\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.2770874  -1.94998784  3.24493623  2.80722481  2.70915504]\n",
      "Norm: 0.048932945789812665\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.31616627 -1.94875762  3.25411152  2.80962767  2.70559747]\n",
      "Norm: 0.039078868883327456\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.30512802 -1.95656057  3.25578145  2.80727397  2.70462487]\n",
      "Norm: 0.011038252969111984\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30409214 -1.95515099  3.25364972  2.8071972   2.70485012]\n",
      "Norm: 0.002131733700984295\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.30518824 -1.95448305  3.25396653  2.80737855  2.70493971]\n",
      "Norm: 0.001096100052800253\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.30523154 -1.95475619  3.25406843  2.80738398  2.70491754]\n",
      "Norm: 0.0002731390071752937\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.30506637 -1.95477526  3.25404848  2.80736823  2.70491054]\n",
      "Norm: 0.0001651694332212017\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.3051053  -1.95474691  3.25403535  2.80736761  2.7049121 ]\n",
      "Norm: 3.892652583648015e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.3051053  -1.95474691  3.25403535  2.80736761  2.7049121 ]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.4000000000000004\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.6      -1.12      2.856     2.35984   3.369184]\n",
      "Norm: 3.3691840000000015\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.288      -2.1728      3.30616533  3.36567019  2.96028524]\n",
      "Norm: 1.3120000000000007\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.18112    -1.94160877  3.48759738  2.75975529  2.55832418]\n",
      "Norm: 0.6059148932424705\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.36258674 -2.00584631  3.1622418   2.73147327  2.69271205]\n",
      "Norm: 0.3253555835697055\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.25145752 -1.93078986  3.24415941  2.82951176  2.73045949]\n",
      "Norm: 0.11112921901300465\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.34094308 -1.94453799  3.26355945  2.81415093  2.70102374]\n",
      "Norm: 0.08948555810866266\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.29689997 -1.96562776  3.25847294  2.80309913  2.70248303]\n",
      "Norm: 0.04404310307465087\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30186336 -1.95329313  3.24959388  2.80709399  2.70562784]\n",
      "Norm: 0.012334621146069313\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.30727878 -1.95293741  3.25484377  2.80799212  2.70520818]\n",
      "Norm: 0.005415419436224145\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.30532604 -1.95562428  3.25441681  2.80733808  2.70476561]\n",
      "Norm: 0.0026868619938082983\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.30449502 -1.95480451  3.25389982  2.80727948  2.70488794]\n",
      "Norm: 0.0008310230712846867\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.30531929 -1.95458692  3.25397772  2.80738234  2.704935  ]\n",
      "Norm: 0.0008242675709970726\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [ 0.30512014 -1.95479113  3.25408986  2.80738325  2.70491703]\n",
      "Norm: 0.00020421173814400007\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.30507727 -1.95476434  3.25403293  2.80736485  2.70490705]\n",
      "Norm: 5.6931592969711176e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30507727 -1.95476434  3.25403293  2.80736485  2.70490705]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.5000000000000004\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.71428571 -1.14285714  3.07142857  2.56071429  3.81071429]\n",
      "Norm: 3.810714285714287\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.12244898 -2.39115646  3.44022109  3.62210459  2.96674745]\n",
      "Norm: 1.591836734693879\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.11588921 -1.89321753  3.53755051  2.59962875  2.36625503]\n",
      "Norm: 1.0224758412293506\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.4392727  -2.01293839  3.03750831  2.67556489  2.74243737]\n",
      "Norm: 0.5000421996959226\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.20061754 -1.9057248   3.27189069  2.89846358  2.7772449 ]\n",
      "Norm: 0.23865515794510306\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.38886814 -1.94333376  3.28495333  2.80985814  2.6712357 ]\n",
      "Norm: 0.18825059988571913\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.27056566 -1.98803473  3.25646978  2.78628281  2.70066496]\n",
      "Norm: 0.11830248349530459\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30098056 -1.94098228  3.23539766  2.81256722  2.71223474]\n",
      "Norm: 0.04705245480027176\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.31602111 -1.94996419  3.26356688  2.81059226  2.70447489]\n",
      "Norm: 0.028169218617167147\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.30272675 -1.96151016  3.25426777  2.80552897  2.70329152]\n",
      "Norm: 0.013294362995414977\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.30195152 -1.95302508  3.25214314  2.8070319   2.70538614]\n",
      "Norm: 0.008485071912670561\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.30779383 -1.95363826  3.25426351  2.80785526  2.70516219]\n",
      "Norm: 0.005842301871880284\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [ 0.30447849 -1.95569613  3.25464394  2.80736628  2.70478518]\n",
      "Norm: 0.003315334712891138\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.30481324 -1.95462663  3.25367448  2.80723914  2.70484655]\n",
      "Norm: 0.001069500087949038\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [ 0.3053334  -1.95457815  3.2540714   2.80739907  2.70497579]\n",
      "Norm: 0.0005201600185764654\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [ 0.30510449 -1.95484915  3.25408841  2.8073992   2.70491131]\n",
      "Norm: 0.00027100463601459346\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [ 0.30504473 -1.9547492   3.25403     2.80735168  2.70489603]\n",
      "Norm: 9.995330672563085e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30504473 -1.9547492   3.25403     2.80735168  2.70489603]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.6000000000000005\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.82857143 -1.15809524  3.28431746  2.76549079  4.28319018]\n",
      "Norm: 4.2831901798941825\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [-0.06269388 -2.63967024  3.57882874  3.89455984  2.91761639]\n",
      "Norm: 1.8912653061224507\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.05612816 -1.79206861  3.55223793  2.33889665  2.0775866 ]\n",
      "Norm: 1.5556631855937\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.56604749 -2.0192181   2.85965178  2.62386172  2.88556721]\n",
      "Norm: 0.8079806074565696\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.10433624 -1.88292156  3.35449334  3.04916492  2.85443559]\n",
      "Norm: 0.4948415620921116\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.47482348 -1.94304996  3.31648526  2.76797747  2.57318128]\n",
      "Norm: 0.3704872392465095\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.21130023 -2.03400466  3.23783265  2.74410276  2.71646751]\n",
      "Norm: 0.26352324726753484\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30704524 -1.90040246  3.20103653  2.8442434   2.73731245]\n",
      "Norm: 0.13360220088772223\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.34121117 -1.94925889  3.3025793   2.81374662  2.69227559]\n",
      "Norm: 0.1015427678762828\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.28721006 -1.98484972  3.24437047  2.79390768  2.69813617]\n",
      "Norm: 0.058208832144701184\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.29520558 -1.93853447  3.24401353  2.80950471  2.71125665]\n",
      "Norm: 0.04631525196079833\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.3221673  -1.95181713  3.25963019  2.81104226  2.70502442]\n",
      "Norm: 0.026961715473220682\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [ 0.29688216 -1.96288553  3.25698337  2.80570761  2.70307347]\n",
      "Norm: 0.025285138768158966\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.30446348 -1.95126002  3.24952605  2.80646662  2.70505365]\n",
      "Norm: 0.01162550375873761\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [ 0.30788646 -1.95375824  3.25573763  2.80827238  2.70579169]\n",
      "Norm: 0.006211581191248872\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [ 0.30411961 -1.95647686  3.25442369  2.80745104  2.70447276]\n",
      "Norm: 0.0037668532539847366\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [ 0.30451553 -1.95416736  3.25354227  2.80695871  2.70473896]\n",
      "Norm: 0.002309506723797705\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [ 0.30586164 -1.95452174  3.25399755  2.80749732  2.70515376]\n",
      "Norm: 0.0013461120528752701\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [ 0.30481097 -1.95503135  3.25428343  2.80748537  2.70489213]\n",
      "Norm: 0.0010506731904396105\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [ 0.30509193 -1.95467738  3.25391674  2.80726642  2.70481557]\n",
      "Norm: 0.0003666845129091101\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [ 0.30516607 -1.95471984  3.25404263  2.80736893  2.70497085]\n",
      "Norm: 0.00015527803964010545\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [ 0.30509247 -1.95477838  3.25405299  2.80740846  2.70491985]\n",
      "Norm: 7.359897507108748e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30509247 -1.95477838  3.25405299  2.80740846  2.70491985]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.7000000000000006\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.94285714 -1.16571429  3.49390476  2.97396381  4.78715898]\n",
      "Norm: 4.787158984126987\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [-0.26644898 -2.921574    3.72840476  4.18732225  2.81128726]\n",
      "Norm: 2.2093061224489814\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 7.96086816e-04 -1.62962222e+00  3.51971853e+00  1.95890191e+00\n",
      "  1.66885442e+00]\n",
      "Norm: 2.2284203378930796\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.7550037  -2.02776713  2.62864282  2.59045894  3.18432204]\n",
      "Norm: 1.515467625998351\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [-0.06301864 -1.87598308  3.52426717  3.33114315  2.9629368 ]\n",
      "Norm: 0.8956243536314235\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.62018252 -1.93343157  3.34960532  2.63242973  2.32603126]\n",
      "Norm: 0.6987134213152957\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.10008638 -2.12195541  3.18276119  2.66006985  2.80319061]\n",
      "Norm: 0.5200961425032704\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.3268006  -1.79848733  3.13191624  2.95654648  2.80518592]\n",
      "Norm: 0.3234680824046827\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.40377025 -1.96209076  3.42821974  2.80074124  2.62720993]\n",
      "Norm: 0.2963035006024102\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.23069471 -2.05758137  3.186629    2.74771081  2.69169197]\n",
      "Norm: 0.24159073820505306\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.28227585 -1.87024101  3.2195324   2.83427348  2.7446589 ]\n",
      "Norm: 0.1873403580474502\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.38265988 -1.95692515  3.29467321  2.82247106  2.69420597]\n",
      "Norm: 0.1003840318444027\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [ 0.24923547 -2.00023995  3.25993166  2.7905187   2.69331035]\n",
      "Norm: 0.1334244109373519\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.31107464 -1.92175281  3.22166836  2.80577157  2.71122387]\n",
      "Norm: 0.07848713628982873\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [ 0.32497071 -1.95436435  3.27557583  2.81644002  2.71077532]\n",
      "Norm: 0.05390746507793054\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [ 0.29148362 -1.97087733  3.25324342  2.80487058  2.69797727]\n",
      "Norm: 0.0334870802515399\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [ 0.3028937  -1.94441585  3.24732525  2.80326043  2.70511106]\n",
      "Norm: 0.026461481616104843\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [ 0.31418573 -1.95430431  3.25615901  2.81074026  2.70859455]\n",
      "Norm: 0.011292030161022204\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [ 0.29907685 -1.95928128  3.25703423  2.80802193  2.70307534]\n",
      "Norm: 0.015108876173330232\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [ 0.30602699 -1.95218963  3.25086259  2.80512252  2.70365278]\n",
      "Norm: 0.007091650623198831\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [ 0.30632866 -1.95465133  3.2549347   2.80823703  2.70677835]\n",
      "Norm: 0.004072108566407273\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [ 0.30432397 -1.95560249  3.2543881   2.80808934  2.70442307]\n",
      "Norm: 0.0023552811791791584\n",
      "\n",
      "Iteration #: 23\n",
      "Approximated Solution:  [ 0.30503427 -1.95432768  3.25396464  2.80651914  2.70429221]\n",
      "Norm: 0.00157019501601674\n",
      "\n",
      "Iteration #: 24\n",
      "Approximated Solution:  [ 0.30546585 -1.95481551  3.25364772  2.80747542  2.70546759]\n",
      "Norm: 0.001175381765377459\n",
      "\n",
      "Iteration #: 25\n",
      "Approximated Solution:  [ 0.30480832 -1.9547269   3.25436124  2.80772658  2.70492948]\n",
      "Norm: 0.0007135206117054871\n",
      "\n",
      "Iteration #: 26\n",
      "Approximated Solution:  [ 0.30533315 -1.95476108  3.25402347  2.80712743  2.70462712]\n",
      "Norm: 0.0005991538696403786\n",
      "\n",
      "Iteration #: 27\n",
      "Approximated Solution:  [ 0.30494087 -1.95483184  3.25396049  2.80733052  2.70506894]\n",
      "Norm: 0.0004418274575881398\n",
      "\n",
      "Iteration #: 28\n",
      "Approximated Solution:  [ 0.30516391 -1.95463213  3.25400649  2.80749662  2.70494791]\n",
      "Norm: 0.00022303765764020156\n",
      "\n",
      "Iteration #: 29\n",
      "Approximated Solution:  [ 0.30515329 -1.95479532  3.25416089  2.80732429  2.70483733]\n",
      "Norm: 0.00017232479650486354\n",
      "\n",
      "Iteration #: 30\n",
      "Approximated Solution:  [ 0.30504182 -1.95480258  3.25395927  2.80733546  2.70492738]\n",
      "Norm: 0.00020161810333796382\n",
      "\n",
      "Iteration #: 31\n",
      "Approximated Solution:  [ 0.30511456 -1.95468011  3.25403733  2.80740215  2.70493993]\n",
      "Norm: 0.00012246533744986188\n",
      "\n",
      "Iteration #: 32\n",
      "Approximated Solution:  [ 0.30515287 -1.95477362  3.25407347  2.80737014  2.70489487]\n",
      "Norm: 9.350856117507078e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30515287 -1.95477362  3.25407347  2.80737014  2.70489487]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.8000000000000007\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 2.05714286 -1.16571429  3.69942857  3.18589714  5.32307657]\n",
      "Norm: 5.323076571428575\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [-0.48783673 -3.23990204  3.89593665  4.50516601  2.64773796]\n",
      "Norm: 2.6753386109387813\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [-0.05194076 -1.39761748  3.42492078  1.43872426  1.10827874]\n",
      "Norm: 3.066441755144962\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 1.0205334  -2.03955428  2.3470305   2.58944678  3.72071314]\n",
      "Norm: 2.6124343960012846\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [-0.33265431 -1.90676136  3.82010048  3.81497412  3.10139844]\n",
      "Norm: 1.4730699793785766\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.85233611 -1.89122943  3.36764175  2.30720309  1.78752496]\n",
      "Norm: 1.5077710338202595\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [-0.08367445 -2.28427782  3.06077515  2.51219502  3.08461406]\n",
      "Norm: 1.2970891040490018\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.36192524 -1.57973266  3.00653649  3.27234267  2.95911996]\n",
      "Norm: 0.7601476492751136\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.54895176 -2.00945742  3.76385086  2.71018539  2.3849265 ]\n",
      "Norm: 0.7573143743552144\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.06782859 -2.25727726  2.9693969   2.60349021  2.71624705]\n",
      "Norm: 0.7944539650528379\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.26155182 -1.62500586  3.16158012  2.96199013  2.88139052]\n",
      "Norm: 0.6322713987587716\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 0.59432545 -2.00803209  3.45274923  2.84650393  2.6106923 ]\n",
      "Norm: 0.3830262265023201\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [ 0.03262917 -2.15509652  3.23876088  2.70547227  2.65801289]\n",
      "Norm: 0.5616962858677177\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.36853649 -1.75030524  3.0824578   2.82423387  2.76267033]\n",
      "Norm: 0.40479128066350634\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [ 0.41207819 -1.98549201  3.41986929  2.86531202  2.72823816]\n",
      "Norm: 0.3374114831896722\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [ 0.19581504 -2.06206508  3.22053083  2.77177741  2.64354237]\n",
      "Norm: 0.21626315611496705\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [ 0.30975491 -1.85270732  3.19826617  2.78161649  2.72310589]\n",
      "Norm: 0.20935776037625087\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [ 0.38010757 -1.96907607  3.2918026   2.84786752  2.73895631]\n",
      "Norm: 0.11636874928283603\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [ 0.23405526 -2.00102702  3.27589465  2.80341556  2.67293363]\n",
      "Norm: 0.14605230689803683\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [ 0.32624923 -1.9137867   3.20960564  2.77950878  2.69706363]\n",
      "Norm: 0.09219396727624796\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [ 0.31979373 -1.96093665  3.27658275  2.82806369  2.73602552]\n",
      "Norm: 0.06697710605896612\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [ 0.28858531 -1.96873259  3.25681157  2.81371351  2.68763579]\n",
      "Norm: 0.048389725721843746\n",
      "\n",
      "Iteration #: 23\n",
      "Approximated Solution:  [ 0.30753804 -1.94321573  3.24870829  2.78889446  2.69656471]\n",
      "Norm: 0.025516857991019437\n",
      "\n",
      "Iteration #: 24\n",
      "Approximated Solution:  [ 0.31206029 -1.95767456  3.24897478  2.81522649  2.72102001]\n",
      "Norm: 0.026332030636002646\n",
      "\n",
      "Iteration #: 25\n",
      "Approximated Solution:  [ 0.29728854 -1.95507714  3.26300236  2.81429364  2.70033636]\n",
      "Norm: 0.020683653203735552\n",
      "\n",
      "Iteration #: 26\n",
      "Approximated Solution:  [ 0.31110966 -1.95447343  3.25085836  2.79796177  2.69728503]\n",
      "Norm: 0.016331874140296243\n",
      "\n",
      "Iteration #: 27\n",
      "Approximated Solution:  [ 0.30051848 -1.95645351  3.25196248  2.80902906  2.71300684]\n",
      "Norm: 0.015721803505012844\n",
      "\n",
      "Iteration #: 28\n",
      "Approximated Solution:  [ 0.30746394 -1.95114382  3.25453374  2.81195775  2.70394383]\n",
      "Norm: 0.009063005198527208\n",
      "\n",
      "Iteration #: 29\n",
      "Approximated Solution:  [ 0.30600362 -1.95729627  3.25792542  2.80369993  2.70128485]\n",
      "Norm: 0.008257820567496132\n",
      "\n",
      "Iteration #: 30\n",
      "Approximated Solution:  [ 0.3024257  -1.95587773  3.24940626  2.80685828  2.70720205]\n",
      "Norm: 0.008519154981001975\n",
      "\n",
      "Iteration #: 31\n",
      "Approximated Solution:  [ 0.30638233 -1.95123092  3.25532851  2.80965799  2.70582794]\n",
      "Norm: 0.005922241627654756\n",
      "\n",
      "Iteration #: 32\n",
      "Approximated Solution:  [ 0.30680171 -1.95706564  3.25577137  2.80650858  2.70314794]\n",
      "Norm: 0.005834721244386554\n",
      "\n",
      "Iteration #: 33\n",
      "Approximated Solution:  [ 0.30196514 -1.95547695  3.25257422  2.80652301  2.70530926]\n",
      "Norm: 0.004836571938284351\n",
      "\n",
      "Iteration #: 34\n",
      "Approximated Solution:  [ 0.30705995 -1.95241215  3.25330172  2.80819857  2.70559087]\n",
      "Norm: 0.005094816561729942\n",
      "\n",
      "Iteration #: 35\n",
      "Approximated Solution:  [ 0.30534838 -1.95618194  3.25598693  2.80754422  2.70458036]\n",
      "Norm: 0.0037697875686368842\n",
      "\n",
      "Iteration #: 36\n",
      "Approximated Solution:  [ 0.30380952 -1.95516351  3.25283509  2.8067728   2.70446307]\n",
      "Norm: 0.003151835219997956\n",
      "\n",
      "Iteration #: 37\n",
      "Approximated Solution:  [ 0.30582625 -1.95350748  3.2539001   2.80749719  2.70542617]\n",
      "Norm: 0.0020167346883841475\n",
      "\n",
      "Iteration #: 38\n",
      "Approximated Solution:  [ 0.30549037 -1.95545983  3.25465413  2.80774683  2.70495527]\n",
      "Norm: 0.0019523517707926707\n",
      "\n",
      "Iteration #: 39\n",
      "Approximated Solution:  [ 0.30425298 -1.954942    3.25388999  2.80707053  2.70452042]\n",
      "Norm: 0.0012373961373775\n",
      "\n",
      "Iteration #: 40\n",
      "Approximated Solution:  [ 0.30564236 -1.95421698  3.25366051  2.80725717  2.70509227]\n",
      "Norm: 0.001389384416170758\n",
      "\n",
      "Iteration #: 41\n",
      "Approximated Solution:  [ 0.30509016 -1.95503653  3.25444781  2.80766131  2.70511975]\n",
      "Norm: 0.0008195459724680276\n",
      "\n",
      "Iteration #: 42\n",
      "Approximated Solution:  [ 0.3048997  -1.95481009  3.25392459  2.8072636   2.70462052]\n",
      "Norm: 0.0005232264325432112\n",
      "\n",
      "Iteration #: 43\n",
      "Approximated Solution:  [ 0.30522675 -1.95458572  3.25396992  2.80723048  2.70498016]\n",
      "Norm: 0.00035963928746962637\n",
      "\n",
      "Iteration #: 44\n",
      "Approximated Solution:  [ 0.30513819 -1.95483648  3.25406424  2.80753289  2.70505534]\n",
      "Norm: 0.00030241279843146174\n",
      "\n",
      "Iteration #: 45\n",
      "Approximated Solution:  [ 0.30501559 -1.95474716  3.25411664  2.80735453  2.70478116]\n",
      "Norm: 0.0002741858619295101\n",
      "\n",
      "Iteration #: 46\n",
      "Approximated Solution:  [ 0.30518258 -1.95473938  3.25396304  2.80727216  2.70490166]\n",
      "Norm: 0.0001669870985514521\n",
      "\n",
      "Iteration #: 47\n",
      "Approximated Solution:  [ 0.30505498 -1.95476072  3.2540493   2.80744034  2.70500708]\n",
      "Norm: 0.00016818637471693876\n",
      "\n",
      "Iteration #: 48\n",
      "Approximated Solution:  [ 0.3051406  -1.95472678  3.25406084  2.80738378  2.70485486]\n",
      "Norm: 0.00015221864563041976\n",
      "\n",
      "Iteration #: 49\n",
      "Approximated Solution:  [ 0.30509828 -1.95478394  3.25405196  2.80731783  2.70489751]\n",
      "Norm: 6.594141908111695e-05\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30509828 -1.95478394  3.25405196  2.80731783  2.70489751]\n",
      "\n",
      "######################################################################################\n",
      "Relaxation Parameter: 1.9000000000000008\n",
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 2.17142857 -1.15809524  3.90012698  3.40102413  5.89129723]\n",
      "Norm: 5.891297227513232\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [-0.72587755 -3.59749035  4.08894488  4.85336371  2.42875986]\n",
      "Norm: 3.4625373707994793\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [-0.10466663 -1.08832428  3.24968533  0.75527037  0.35412526]\n",
      "Norm: 4.0980933384023785\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 1.37942163 -2.05229715  2.02007596  2.6332063   4.60001524]\n",
      "Norm: 4.245889983208112\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [-0.74120714 -2.00861805  4.28842039  4.60092579  3.27115895]\n",
      "Norm: 2.268344429220586\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 1.20292601 -1.77439033  3.34478853  1.64075741  0.717583  ]\n",
      "Norm: 2.9601683815366044\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [-0.35606554 -2.57413425  2.82578838  2.2655812   3.80724483]\n",
      "Norm: 3.089661826768334\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.39580681 -1.15904551  2.79238738  4.04503659  3.280526  ]\n",
      "Norm: 1.7794553828625572\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.87140824 -2.11730849  4.55633658  2.37837078  1.64346292]\n",
      "Norm: 1.7639491983328592\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [-0.3369329  -2.76493309  2.32338953  2.20994213  2.90347673]\n",
      "Norm: 2.232947044727881\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.22322267 -0.88450589  3.03543317  3.4544267   3.34581143]\n",
      "Norm: 1.8804271976716291\n",
      "\n",
      "Iteration #: 12\n",
      "Approximated Solution:  [ 1.25028766 -2.22705652  4.03304953  2.86011206  2.19491166]\n",
      "Norm: 1.3425506341143152\n",
      "\n",
      "Iteration #: 13\n",
      "Approximated Solution:  [-0.76729063 -2.71777633  3.06958474  2.33725311  2.56843344]\n",
      "Norm: 2.017578287650199\n",
      "\n",
      "Iteration #: 14\n",
      "Approximated Solution:  [ 0.6489437  -0.97238385  2.5001438   2.98350894  3.05085456]\n",
      "Norm: 1.7453924769266362\n",
      "\n",
      "Iteration #: 15\n",
      "Approximated Solution:  [ 0.79558096 -2.2099362   4.20571916  3.09257806  2.75482977]\n",
      "Norm: 1.7055753582162314\n",
      "\n",
      "Iteration #: 16\n",
      "Approximated Solution:  [-0.34411377 -2.53807757  2.94760132  2.53039462  2.30915306]\n",
      "Norm: 1.2581178435929816\n",
      "\n",
      "Iteration #: 17\n",
      "Approximated Solution:  [ 0.41441066 -1.23114622  2.89613468  2.68786675  2.9097268 ]\n",
      "Norm: 1.3069313496698214\n",
      "\n",
      "Iteration #: 18\n",
      "Approximated Solution:  [ 0.7959542  -2.14400983  3.62033396  3.14017574  2.94213515]\n",
      "Norm: 0.912863610861627\n",
      "\n",
      "Iteration #: 19\n",
      "Approximated Solution:  [-0.29076678 -2.31646223  3.36423682  2.70906954  2.36689978]\n",
      "Norm: 1.0867209862358365\n",
      "\n",
      "Iteration #: 20\n",
      "Approximated Solution:  [ 0.54685657 -1.52263037  2.81893014  2.55627797  2.69107563]\n",
      "Norm: 0.8376233577618677\n",
      "\n",
      "Iteration #: 21\n",
      "Approximated Solution:  [ 0.43940149 -2.07489333  3.5627047   3.08148119  3.06457478]\n",
      "Norm: 0.743774559676261\n",
      "\n",
      "Iteration #: 22\n",
      "Approximated Solution:  [ 0.08641123 -2.11545532  3.25162556  2.83355262  2.41438268]\n",
      "Norm: 0.6501921036827647\n",
      "\n",
      "Iteration #: 23\n",
      "Approximated Solution:  [ 0.37107342 -1.76731895  3.15408899  2.54401039  2.63280208]\n",
      "Norm: 0.3481363697548723\n",
      "\n",
      "Iteration #: 24\n",
      "Approximated Solution:  [ 0.39835992 -2.02217812  3.21990597  2.98310237  2.99240779]\n",
      "Norm: 0.4390919796804491\n",
      "\n",
      "Iteration #: 25\n",
      "Approximated Solution:  [ 0.16627389 -1.96758208  3.40418478  2.8962329   2.55872799]\n",
      "Norm: 0.4336797993156831\n",
      "\n",
      "Iteration #: 26\n",
      "Approximated Solution:  [ 0.41960809 -1.93408013  3.16209862  2.5988224   2.57231985]\n",
      "Norm: 0.29741049582618695\n",
      "\n",
      "Iteration #: 27\n",
      "Approximated Solution:  [ 0.21888747 -1.98914079  3.22648793  2.88905563  2.92771593]\n",
      "Norm: 0.355396083935795\n",
      "\n",
      "Iteration #: 28\n",
      "Approximated Solution:  [ 0.35470092 -1.88075761  3.28370925  2.9088188   2.6328928 ]\n",
      "Norm: 0.29482313049290587\n",
      "\n",
      "Iteration #: 29\n",
      "Approximated Solution:  [ 0.32072369 -2.0239815   3.3354352   2.6767943   2.60433592]\n",
      "Norm: 0.23202449845011897\n",
      "\n",
      "Iteration #: 30\n",
      "Approximated Solution:  [ 0.23467803 -1.97141543  3.10864115  2.82082225  2.81247252]\n",
      "Norm: 0.22679404935957992\n",
      "\n",
      "Iteration #: 31\n",
      "Approximated Solution:  [ 0.35492292 -1.8468123   3.32505818  2.89050014  2.71340825]\n",
      "Norm: 0.21641703447200555\n",
      "\n",
      "Iteration #: 32\n",
      "Approximated Solution:  [ 0.34816507 -2.05461117  3.30601814  2.74888359  2.62318512]\n",
      "Norm: 0.20779886806422798\n",
      "\n",
      "Iteration #: 33\n",
      "Approximated Solution:  [ 0.18503949 -1.96286593  3.17535837  2.78294355  2.74752856]\n",
      "Norm: 0.16312557909535386\n",
      "\n",
      "Iteration #: 34\n",
      "Approximated Solution:  [ 0.40655935 -1.84997328  3.24302479  2.85964722  2.73277744]\n",
      "Norm: 0.22151986429900639\n",
      "\n",
      "Iteration #: 35\n",
      "Approximated Solution:  [ 0.29911834 -2.0481929   3.3562431   2.80091454  2.67165873]\n",
      "Norm: 0.19821962330062548\n",
      "\n",
      "Iteration #: 36\n",
      "Approximated Solution:  [ 0.23440784 -1.95858184  3.16039559  2.7701127   2.6876499 ]\n",
      "Norm: 0.19584750415396757\n",
      "\n",
      "Iteration #: 37\n",
      "Approximated Solution:  [ 0.3656163  -1.87344194  3.26322857  2.82952592  2.74851459]\n",
      "Norm: 0.13120845776980516\n",
      "\n",
      "Iteration #: 38\n",
      "Approximated Solution:  [ 0.3168569  -2.02436718  3.30389325  2.83003747  2.69438434]\n",
      "Norm: 0.15092524017605458\n",
      "\n",
      "Iteration #: 39\n",
      "Approximated Solution:  [ 0.23784409 -1.95574543  3.22415858  2.7732885   2.67121953]\n",
      "Norm: 0.07973466231319515\n",
      "\n",
      "Iteration #: 40\n",
      "Approximated Solution:  [ 0.36483332 -1.90341274  3.22683473  2.80726579  2.73510576]\n",
      "Norm: 0.1269892300843094\n",
      "\n",
      "Iteration #: 41\n",
      "Approximated Solution:  [ 0.29315678 -1.99703724  3.30524066  2.84013689  2.71924488]\n",
      "Norm: 0.0936244934073589\n",
      "\n",
      "Iteration #: 42\n",
      "Approximated Solution:  [ 0.28142858 -1.95330778  3.22779836  2.7837846   2.6621401 ]\n",
      "Norm: 0.07744230194561297\n",
      "\n",
      "Iteration #: 43\n",
      "Approximated Solution:  [ 0.32759223 -1.93072945  3.24750704  2.79484668  2.72754637]\n",
      "Norm: 0.06540627058279469\n",
      "\n",
      "Iteration #: 44\n",
      "Approximated Solution:  [ 0.30443015 -1.9740407   3.26420567  2.83777231  2.72305319]\n",
      "Norm: 0.043311251214428914\n",
      "\n",
      "Iteration #: 45\n",
      "Approximated Solution:  [ 0.29000829 -1.95124496  3.26192583  2.79529126  2.67328772]\n",
      "Norm: 0.049765475712427065\n",
      "\n",
      "Iteration #: 46\n",
      "Approximated Solution:  [ 0.32155022 -1.95082197  3.23680513  2.79092951  2.71255177]\n",
      "Norm: 0.039264048205533975\n",
      "\n",
      "Iteration #: 47\n",
      "Approximated Solution:  [ 0.29350691 -1.9583569   3.26142344  2.82937324  2.72590951]\n",
      "Norm: 0.038443728026451573\n",
      "\n",
      "Iteration #: 48\n",
      "Approximated Solution:  [ 0.3126103  -1.94987105  3.25824028  2.80432097  2.68215467]\n",
      "Norm: 0.04375484442647304\n",
      "\n",
      "Iteration #: 49\n",
      "Approximated Solution:  [ 0.30232716 -1.96267698  3.25334911  2.79268501  2.70679514]\n",
      "Norm: 0.024640473045603795\n",
      "\n",
      "Iteration #: 50\n",
      "Approximated Solution:  [ 0.30115431 -1.94982929  3.24224485  2.81977432  2.71893185]\n",
      "Norm: 0.0270893179015248\n",
      "\n",
      "Number of Iterations Exceeded. Solution did not converge!\n",
      "Latest Approximated Solution: \n",
      "[ 0.30115431 -1.94982929  3.24224485  2.81977432  2.71893185]\n",
      "\n",
      "######################################################################################\n"
     ]
    }
   ],
   "source": [
    "def sor_method(A, b, min_tol=1e-4, max_tol = 1e4, iter_max=100, omega=1):\n",
    "    norm = []\n",
    "    x = []\n",
    "    iteration = []\n",
    "    L = len(b)\n",
    "\n",
    "    xn = np.zeros(L)\n",
    "    x0 = np.zeros(L)\n",
    "    print('x0: ',x0)\n",
    "    print()\n",
    "\n",
    "    for itr in range(1,iter_max+1):\n",
    "        print(f'Iteration #: {itr}')\n",
    "        for i in range(0,L):\n",
    "            xn[i] = (1-w)*x0[i] + (w*b[i])/A[i,i]\n",
    "            for j in range(0,L): \n",
    "                if (j<i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*xn[j])*(w/A[i,i])\n",
    "                if (j>i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*x0[j])*(w/A[i,i])\n",
    "        print('Approximated Solution: ', xn)\n",
    "        x.append(xn)\n",
    "    \n",
    "        #Stop condition \n",
    "        stop = np.linalg.norm(xn - x0, ord=np.inf)\n",
    "        norm.append(stop)\n",
    "        print(f'Norm: {stop}')\n",
    "        print()\n",
    "        \n",
    "        if stop <= min_tol:\n",
    "            print('Solution Converged!')\n",
    "            print('Best Approximated Solution: ')\n",
    "            iteration.append(itr)\n",
    "            break\n",
    "        elif stop >= max_tol:\n",
    "            print('Solution Diverged!')\n",
    "            print('Latest Approximated Solution: ')\n",
    "            iteration.append(itr)\n",
    "            break\n",
    "    \n",
    "        x0 = xn\n",
    "        xn = np.zeros(L)\n",
    "    \n",
    "    if itr>=iter_max:\n",
    "        print('Number of Iterations Exceeded. Solution did not converge!')\n",
    "        print('Latest Approximated Solution: ')\n",
    "        iteration.append(itr)\n",
    "        \n",
    "    return xn, norm, x, iteration\n",
    "\n",
    "solution = []\n",
    "iteration = []\n",
    "\n",
    "for w in np.arange(1.1,2,0.1):\n",
    "    print(f'Relaxation Parameter: {w}')\n",
    "    ans, error, x, itr = sor_method(A, b, iter_max=50, omega = w)\n",
    "    iteration.append(itr[-1])\n",
    "    solution.append(x[-1])\n",
    "    print(x[-1])\n",
    "    print()\n",
    "    print('######################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relaxation Parameter $(\\omega)$</th>\n",
       "      <th>Number of Iterations</th>\n",
       "      <th>Approximated Solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.3051101584565574, -1.954749647146926, 3.2540394768036203, 2.8073689751039046, 2.7049126959266823]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.30507850938951164, -1.9547573752778435, 3.254040121340143, 2.807368031916268, 2.704911840327871]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.30510530015142834, -1.954746906945906, 3.25403534882354, 2.8073676058819794, 2.7049120976861207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.3050772685540317, -1.9547643352001258, 3.254032928370397, 2.807364847621849, 2.704907045624876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.3050447298046377, -1.9547491964520671, 3.254029995166847, 2.807351681230508, 2.7048960285247006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.6</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.30509246784167265, -1.9547783799679208, 3.2540529891768797, 2.807408463230333, 2.70491984991053]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.7</td>\n",
       "      <td>32</td>\n",
       "      <td>[0.305152867393784, -1.9547736214928872, 3.2540734706730685, 2.8073701404087155, 2.7048948727457005]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.8</td>\n",
       "      <td>49</td>\n",
       "      <td>[0.30509828470565314, -1.9547839379131475, 3.2540519561074435, 2.8073178339989635, 2.704897509427579]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.9</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.30115430624152917, -1.949829285276604, 3.242244852860898, 2.8197743234793693, 2.718931850341053]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relaxation Parameter $(\\omega)$  Number of Iterations  \\\n",
       "0  1.1                              8                      \n",
       "1  1.2                              9                      \n",
       "2  1.3                              12                     \n",
       "3  1.4                              14                     \n",
       "4  1.5                              17                     \n",
       "5  1.6                              22                     \n",
       "6  1.7                              32                     \n",
       "7  1.8                              49                     \n",
       "8  1.9                              50                     \n",
       "\n",
       "                                                                                   Approximated Solution  \n",
       "0  [0.3051101584565574, -1.954749647146926, 3.2540394768036203, 2.8073689751039046, 2.7049126959266823]   \n",
       "1  [0.30507850938951164, -1.9547573752778435, 3.254040121340143, 2.807368031916268, 2.704911840327871]    \n",
       "2  [0.30510530015142834, -1.954746906945906, 3.25403534882354, 2.8073676058819794, 2.7049120976861207]    \n",
       "3  [0.3050772685540317, -1.9547643352001258, 3.254032928370397, 2.807364847621849, 2.704907045624876]     \n",
       "4  [0.3050447298046377, -1.9547491964520671, 3.254029995166847, 2.807351681230508, 2.7048960285247006]    \n",
       "5  [0.30509246784167265, -1.9547783799679208, 3.2540529891768797, 2.807408463230333, 2.70491984991053]    \n",
       "6  [0.305152867393784, -1.9547736214928872, 3.2540734706730685, 2.8073701404087155, 2.7048948727457005]   \n",
       "7  [0.30509828470565314, -1.9547839379131475, 3.2540519561074435, 2.8073178339989635, 2.704897509427579]  \n",
       "8  [0.30115430624152917, -1.949829285276604, 3.242244852860898, 2.8197743234793693, 2.718931850341053]    "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = np.arange(1.1,2,0.1)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "df = pd.DataFrame({r'Relaxation Parameter $(\\omega)$':omega, \n",
    "                   'Number of Iterations': iteration,\n",
    "                   'Approximated Solution':solution})\n",
    "df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pagebreak$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEbCAYAAADXk4MCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(1.1,2,0.1)\n",
    "y = iteration\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(x,y,'-o')\n",
    "plt.title(r'Relaxation Parameter $(\\omega)$ vs. Number of Iterations')\n",
    "plt.xlabel(r'Relaxation Parameter $(\\omega)$')\n",
    "plt.ylabel('Number of Iterations')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the relaxation number increases the number of iteration also increases.\n",
    "* For $\\omega = 1.9$, the solution does not converge as the error norm is higher than the convergence criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pagebreak$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:  [0. 0. 0. 0. 0.]\n",
      "\n",
      "Iteration #: 1\n",
      "Approximated Solution:  [ 1.14285714 -0.95238095  1.98412698  1.5984127   1.8989418 ]\n",
      "Norm: 1.98413\n",
      "\n",
      "Iteration #: 2\n",
      "Approximated Solution:  [ 0.73469388 -1.52935248  2.70925506  2.43050223  2.45366815]\n",
      "Norm: 0.83209\n",
      "\n",
      "Iteration #: 3\n",
      "Approximated Solution:  [ 0.48742036 -1.77291656  3.06780626  2.68824789  2.62549859]\n",
      "Norm: 0.35855\n",
      "\n",
      "Iteration #: 4\n",
      "Approximated Solution:  [ 0.38303576 -1.88738947  3.19187912  2.76938735  2.67959157]\n",
      "Norm: 0.12407\n",
      "\n",
      "Iteration #: 5\n",
      "Approximated Solution:  [ 0.33397594 -1.93131449  3.23356728  2.79519335  2.69679557]\n",
      "Norm: 0.04906\n",
      "\n",
      "Iteration #: 6\n",
      "Approximated Solution:  [ 0.31515093 -1.94685353  3.24734896  2.80345312  2.70230208]\n",
      "Norm: 0.01883\n",
      "\n",
      "Iteration #: 7\n",
      "Approximated Solution:  [ 0.30849134 -1.95213599  3.25186304  2.80610714  2.70407142]\n",
      "Norm: 0.00666\n",
      "\n",
      "Iteration #: 8\n",
      "Approximated Solution:  [ 0.30622743 -1.95389375  3.25333363  2.80696193  2.70464129]\n",
      "Norm: 0.00226\n",
      "\n",
      "Iteration #: 9\n",
      "Approximated Solution:  [ 0.30547411 -1.95447166  3.2538112   2.80723764  2.70482509]\n",
      "Norm: 0.00075\n",
      "\n",
      "Iteration #: 10\n",
      "Approximated Solution:  [ 0.30522643 -1.95466034  3.25396599  2.80732664  2.70488442]\n",
      "Norm: 0.00025\n",
      "\n",
      "Iteration #: 11\n",
      "Approximated Solution:  [ 0.30514557 -1.9547217   3.25401611  2.80735538  2.70490359]\n",
      "Norm: 0.00008\n",
      "\n",
      "Solution Converged!\n",
      "Best Approximated Solution: \n",
      "[ 0.30514557 -1.9547217   3.25401611  2.80735538  2.70490359]\n"
     ]
    }
   ],
   "source": [
    "# Reset Formatter\n",
    "#np.set_printoptions()\n",
    "\n",
    "def gauss_seidel(A, b, min_tol=1e-4, max_tol = 1e4, iter_max=100):\n",
    "    norm = []\n",
    "    x = []\n",
    "    L = len(b)\n",
    "\n",
    "    xn = np.zeros(L)\n",
    "    x0 = np.zeros(L)\n",
    "    print('x0: ',x0)\n",
    "    print()\n",
    "\n",
    "    for itr in range(1,iter_max+1):\n",
    "        print(f'Iteration #: {itr}')\n",
    "        for i in range(0,L):\n",
    "            xn[i] = b[i]/A[i,i]\n",
    "            for j in range(0,L): \n",
    "                if (j<i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*xn[j])/A[i,i]\n",
    "                if (j>i):\n",
    "                    xn[i] =  xn[i]-(A[i,j]*x0[j])/A[i,i]\n",
    "        print('Approximated Solution: ', xn)\n",
    "        x.append(xn)\n",
    "    \n",
    "        #Stop condition \n",
    "        stop = np.linalg.norm(xn - x0, ord=np.inf)\n",
    "        norm.append(stop)\n",
    "        print(f'Norm: {stop:.5f}')\n",
    "        print()\n",
    "        \n",
    "        if stop <= min_tol:\n",
    "            print('Solution Converged!')\n",
    "            print('Best Approximated Solution: ')\n",
    "            break\n",
    "        elif stop >= max_tol:\n",
    "            print('Solution Diverged!')\n",
    "            print('Latest Approximated Solution: ')\n",
    "            break\n",
    "    \n",
    "        x0 = xn\n",
    "        xn = np.zeros(L)\n",
    "        \n",
    "    return xn, norm, x\n",
    "\n",
    "ans, error, x = gauss_seidel(A, b, iter_max=50)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gauss Seidel method takes 11 iterations to converge for the given system of equations.\n",
    "* For 1.1$\\leq \\omega \\leq$1.2, the SOR method performs better than Gauss Seidel, as it takes lesser number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Norm</th>\n",
       "      <th>Approximate Solution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.984127</td>\n",
       "      <td>[1.1428571428571428, -0.9523809523809523, 1.9841269841269842, 1.5984126984126983, 1.8989417989417987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.832090</td>\n",
       "      <td>[0.7346938775510203, -1.529352481733434, 2.709255060048711, 2.4305022255815905, 2.453668150387727]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358551</td>\n",
       "      <td>[0.4874203649713853, -1.772916558353696, 3.0678062613117625, 2.688247886286267, 2.6254985908575112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124073</td>\n",
       "      <td>[0.3830357607055588, -1.8873894711674275, 3.1918791191512317, 2.7693873482581277, 2.6795915655054183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049060</td>\n",
       "      <td>[0.33397594092824534, -1.9313144906130806, 3.233567279623736, 2.7951933541645406, 2.6967955694430272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018825</td>\n",
       "      <td>[0.315150932594394, -1.9468535290515878, 3.247348961072043, 2.803453123884415, 2.70230208258961]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006660</td>\n",
       "      <td>[0.30849134469217654, -1.9521359875630617, 3.251863037149159, 2.80610713675076, 2.7040714245005066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002264</td>\n",
       "      <td>[0.30622743390154494, -1.9538937525104092, 3.2533336297537234, 2.806961932775575, 2.70464128851705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000753</td>\n",
       "      <td>[0.30547410606696745, -1.9544716601451717, 3.253811197640249, 2.8072376351708446, 2.7048250901138964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>[0.30522643136635497, -1.9546603445757147, 3.2539659932488534, 2.807326635370444, 2.704884423580296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>[0.3051455666104078, -1.954721698518498, 3.2540161112963144, 2.8073553805617495, 2.704903587041166]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Error Norm  \\\n",
       "Iteration #               \n",
       "1            1.984127     \n",
       "2            0.832090     \n",
       "3            0.358551     \n",
       "4            0.124073     \n",
       "5            0.049060     \n",
       "6            0.018825     \n",
       "7            0.006660     \n",
       "8            0.002264     \n",
       "9            0.000753     \n",
       "10           0.000248     \n",
       "11           0.000081     \n",
       "\n",
       "                                                                                              Approximate Solution  \n",
       "Iteration #                                                                                                         \n",
       "1            [1.1428571428571428, -0.9523809523809523, 1.9841269841269842, 1.5984126984126983, 1.8989417989417987]  \n",
       "2            [0.7346938775510203, -1.529352481733434, 2.709255060048711, 2.4305022255815905, 2.453668150387727]     \n",
       "3            [0.4874203649713853, -1.772916558353696, 3.0678062613117625, 2.688247886286267, 2.6254985908575112]    \n",
       "4            [0.3830357607055588, -1.8873894711674275, 3.1918791191512317, 2.7693873482581277, 2.6795915655054183]  \n",
       "5            [0.33397594092824534, -1.9313144906130806, 3.233567279623736, 2.7951933541645406, 2.6967955694430272]  \n",
       "6            [0.315150932594394, -1.9468535290515878, 3.247348961072043, 2.803453123884415, 2.70230208258961]       \n",
       "7            [0.30849134469217654, -1.9521359875630617, 3.251863037149159, 2.80610713675076, 2.7040714245005066]    \n",
       "8            [0.30622743390154494, -1.9538937525104092, 3.2533336297537234, 2.806961932775575, 2.70464128851705]    \n",
       "9            [0.30547410606696745, -1.9544716601451717, 3.253811197640249, 2.8072376351708446, 2.7048250901138964]  \n",
       "10           [0.30522643136635497, -1.9546603445757147, 3.2539659932488534, 2.807326635370444, 2.704884423580296]   \n",
       "11           [0.3051455666104078, -1.954721698518498, 3.2540161112963144, 2.8073553805617495, 2.704903587041166]    "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "df = pd.DataFrame(list(zip(error, x)), index =[*range(1, len(error)+1)], columns =['Error Norm','Approximate Solution'])\n",
    "df.index.names = ['Iteration #']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
